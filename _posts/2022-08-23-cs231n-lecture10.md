---
layout: post
title: CS231n Lecture9 Review
category: CS231n
tag: CS231n
---

[![Hits](https://hits.sh/museonghwang.github.io.svg?view=today-total&style=for-the-badge&label=Visitors&color=007ec6)](https://hits.sh/museonghwang.github.io/)

<br>

해당 게시물은 [Standford 2017 CS231n](http://cs231n.stanford.edu/2017/syllabus.html) 강의와 2022년 슬라이드를 바탕으로 작성되었습니다.




<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187315843-99be44b5-699e-4a81-8a1e-a671c85ce9ef.png">
</p>





# Last Time: CNN Architectures

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187316177-c6a65c59-6898-488e-bd62-5accf75add57.png">
</p>

* 지난 강의에서는 CNN 아키텍쳐들을 배웠습니다.
* ImageNet Classification Challenge를 중심으로 연대순 우승자들을 알아봤습니다.
* 2012년에는 AlexNet이 있었으며, AlexNet이 Computer Vision의 진화를 촉발시켜 딥러닝 시대의 서막을 열었습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187316195-5c9c5940-0aa8-41bf-be7b-2a7accc526f3.png">
</p>

* 2014년, 이전의 모델들보다 훨씬 더 깊어진 두 모델인 VGG와 GoogLeNet 입니다.
* Batch normalization이 발명되기 전 모델로, 레이어가 깊은 모델을 학습시키는 일은 상당히 어려웠지만, 이 두 모델은 깊은 모델을 수렴시키기 위해서 각종 테크닉(hackery)을 썼습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187316211-6e06b9f9-96ef-4e6c-9f58-2d3e5da55d1f.png">
</p>

* 2015년에는 ResNet이라는 아주 멋드러진 모델이 있었습니다.
* ResNet은 shortcut connection과 residual block이 도입된 모델입니다.
* ResNet에서 레이어의 출력은 (input + residual block의 output) 입니다. 이 구조는 큰 특징을 가지고 있습니다.
    1. residual block의 가중치가 0이면 이 block은 indentity mapping을 합니다.
        * 모델이 "필요없는 레이어" 를 사용하지 않도록 학습하는데 아주 유용합니다.
        * ResNet의 관점에서 L2 Regularization으로 해석할 수 있는데, 레이어에 L2 Regularization을 추가시키면 L2는 모든 파라미터가 0이 되도록 노력할 것이며, 파라미터들을 계속 0으로 보내면 residual block이 identity가 되기 때문에, ResNet의 관점에서는 파라미터를 0으로 만드려는 속성은 모델이 불필요한 레이어를 사용하지 않도록 해줄 수 있습니다.
    2. backward pass 에서의 gradient flow
        * "Addition gates"가 backward pass시 Upstream gradient가 두 갈래로 나눠지게 됩니다.
        * Upstream gradient가 오면 convolution block으로도 흘러들어가지만, residual connection 덕분에 현재 레이어를 생략하고 직접 이전 레이어로 흘러갈 수도 있습니다.
        * gradient를 원활하게 전달하기 위해, Residual connection은 gradient를 위한 일종의 고속도로 역할을 하여 학습을 더 쉽고 빠르게 할 수 있고, 모델이 엄청 깊더라도 잘 수렴할 수 있도록 도와줍니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187316227-c9df9701-1450-4076-affd-9270fd11be5d.png">
</p>

* DensNet, FractalNet 과 같이 발전된 CNN 아키텍쳐도 살펴보았습니다.
* 이 모델들은 gradient flow의 관점에서 모델 내부에 additional shortcut (identity)를 추가합니다.
    * Loss와 각 Layer를 직접 연결하기 때문에 backward pass가 아주 수월합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187317794-97caeada-95d0-4695-a834-7e67ad17c32e.png">
</p>

* 모델 별 연산량, 크기에 관한 그래프입니다.
* AlexNet와 VGGNet는 파라미터가 엄청 많습니다.
    * 파라미터가 많은 이유는 FC-layer 때문입니다.
* GoogLeNet 이나 ResNet 같은 아키텍쳐들은 FC-Layer를 Global Average Pooling(GAP)으로 대체시켜 파라미터 갯수를 상당히 감소시켰습니다.

<br>
<br>





# Recurrent Neural Networks

* RNN의 기본 구조의 개요를 살펴보고, Vanilla RNN의수식 및 computational graph를 살펴본 후, vanilla RNN에서 생기는 문제를 해결하기 위해 나온 RNN 변형 구조들을 알아보겠습니다.
* 우선 RNN(언어에 관련된 task에 RNN을 많이 활용)이 CNN(이미지에 관련된 task에 RNN을 많이 활용)이나 Fully-Connected NN과 어떤 측면에서 다른지 살펴보겠습니다.

<br>





# “Vanilla” Neural Network

## one to one

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187318258-69e13a22-237f-421f-9fa9-86155beca5dc.png">
</p>

* 지금까지 다루었던 아키텍쳐들은(Vanilla Neural Network), 예를들어 CNN이나 Fully-Connected NN은 input이 1개, output이 1개인, single-input single-output 형태로, 각 layer가 다음 layer로 feed하는 형태의 “Feed-forward” network 였습니다.
* 하나의 입력(image or vector)을 받아 category label을 output으로 출력을 하는 Image Classification이 전형적인 예시입니다.
    * 예를 들어, single image가 input되면, 어떠한 모델 아키텍쳐를 거쳐서 이미지에 대한 label(개 / 고양이 등)을 output으로 반환합니다.
* 이러한 기본적인 (vanilla) NN 를 one-to-one 구조라고 합니다.

<br>

# Recurrent Neural Networks: Process Sequences

하지만 Machine Learning의 관점에서 생각해보면, 다양한 task 들을 해결하기 위해서는 neural network는 task에 따라 다양한 입력과 다양한 출력을 낼 수 있도록 유연한(flexible) 구조를 가져야합니다. sequence, 즉 순서가 있는 시계열 데이터를 다루며 입력과 출력의 크기가 자유로운 RNN은 네트워크가 다양한 입/출력을 다룰 수 있는 여지를 제공해줍니다.

<br>

## one to many

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187322474-7c237e00-38b5-469d-8b80-51b48630f3ec.png">
</p>

* flexible한 형태로 one-to-many 형태가 있습니다.
* one-to-many는 single-input(image)를 입력으로 받아서 output을 더이상 lable형태가 아닌 sequence 형태로 내보내는 것입니다.
    * 예를 들어, single image를 input으로 읽으면, image 내용을 설명하는 sequence of words를 output으로 내보내는(어떠한 연산을 거쳐서 문장(연속적인 단어들)을 출력하는) Image Captioning이 있습니다.
        * input: dog image
        * output: words vector('A', 'dog', 'cute', ...)

<br>

## many to one

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187322487-5a7d244b-f7f3-4d8c-83d8-9bee8f6a3ac0.png">
</p>

* 또다른 형태로 many-to-one 형태가 있습니다.
* input이 더이상 single-input이 아니라, 여러 개의 variable-input을 받아 하나의 output을 생성하는 형태입니다.
    * 예를 들어, 여러개의 단어로 이루어진 문장을 입력으로 받아, 해당 문장의 감정(긍정인지 부정인지)을 구별하는 Sentiment classification이 있습니다.

<br>

## many to many

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187322496-5b3d86cb-eb4f-4e93-99ee-b9433ec6da4e.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187322508-42495c5e-1eec-4183-8cc8-64c44c7e9ed7.png">
</p>

* 또다른 형태로 many-to-many 형태가 있습니다.
* 여러 개의 variable input을 받아 여러개의 variable output을 생성하는 형태를 볼 수 있습니다.(입력과 출력의 길이가 다른 경우)
    * input이 sequence이고 output도 sequence인 many-to-many 형태에서는, input sequence와 output sequence의 길이가 다른 경우인 Machine Translation 형태를 볼 수 있으며, 이를 sequence-to-sequence problem 이라고 합니다.
* 여러 개의 variable input을 받아 하나의 input마다 하나의 output을 생성하는 형태를 볼 수 있습니다.(입력과 출력의 길이가 같은 경우)
    * 또다른 sequence-to-sequence problem에서는 many-to-one과 다르게 video frame별 classification label을 결정하는, sequence of images를 input으로 받아 sequence of labels을 출력으로 보내는 Per-frame video classification을 생각해 볼 수 있습니다.

<br>

neural network를 one-to-one 형태가 아닌 sequence-to-sequence 형태로 만들어 사용하여 훨씬 더 일반적이고 다양한 문제들을 다룰 수 있으며, sequence-to-sequence process의 일반적인 방법론중 하나인 Recurrent Neural Network(RNN)를 다루겠습니다.

| Type | Example | Flow | Description |
| ---- | ------- | ---- | ------------ |
| One-to-One | Image classification | Image -> Label | image를 입력으로 받아 label을 출력 |
| One-to-Many | Image Captioning | Image → Sequence of words | image를 입력으로 받아 이미지를 설명하는 문장을 생성 |
| Many-to-One | Video Classification | Sequence of images -> Label | 비디오 프레임의 sequence를 입력으로 받아 label을 출력 |
| Many-to-One | Action Prediction | Sequence of video frames -> Action class | 비디오 프레임의 sequence를 입력으로 받아 label을 출력 |
| Many-to-One | Sentiment Classification | Sequence of words -> Sentiment | 문장을 입력으로 받아 문장의 감정을 분류 |
| Many-to-Many | Machine Translation | Sequence of words -> Sequence of words | 여러 개의 문장을 입력받아 번역(영어를 입력으로 받아 한국어로 번역) |
| Many-to-Many | Per-frame Video classification | Sequence of images -> Sequence of labels | 비디오 프레임별로 내용이 다를 때, 프레임의 sequence 각각에 대해 label을 출력 |

<br>
<br>





# Sequential Processing of Non-Sequence Data

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187327537-880f2fed-9ea5-4408-ba24-c6e79e9f2c91.gif">
</p>

* Recurrent Neural Network는 Non-Sequential data에도 유용하게 사용되기도 합니다.
    * 즉 RNN은 고정된 하나의 input과 ouput이 필요한 상황(one-to-one) 이더라도 sequential processing 이 필요한 경우 유용하게 사용될 수 있습니다.
* 위 슬라이드는 Non-Sequential data에 sequential processing을 적용한 한 예로, 이미지 분류 문제에 한번의 Feed-forward network를 통해 class를 분류하는 것이 아닌, image의 여러 부분을 순차적으로 살펴보는, 여러개의 glimpses(한 부분)들의 series를 보는 형태의 neural network를 통해 image의 class를 분류할 수도 있습니다.
    * 동작 방식은 step마다 이미지의 한 부분(glimpses)을 보고, 또 다른 부분을 보는 과정을 여러 번 반복하고 최종적으로 분류를 수행하는 것인데, 다음 단계에 이미지의 어디를 보아야 할지는 이전 단계에서 수행한 정보에 따라서 이루어집니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187327545-178ef2ba-f186-41b0-8831-44ae5402877a.gif">
</p>

* Non-Sequential data를 가지고 sequential processing을 사용하는 또다른 예로 digits image를 순차적으로 전체 출력의 일부분씩 생성(generative)하는 neural network가 있습니다.
* 앞의 예와 반대로, 매 순간마다 신경망은 캔버스의 어느 지점에 그려야할지를 판단하고, 그리는 것을 반복하는 것입니다.
    * 마찬가지로 해당 모델에서도 이전에 그렸던 정보에 따라서 다음에는 어디에 그릴지를 판단합니다.

<br>
<br>





# Recurrent Neural Network

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187329443-f0df7057-a1a1-45a0-bee4-068a7cfb9148.png">
</p>

* RNN의 동작 구조를 살펴보겠습니다.
* RNN은 내부에 시퀀스가 처리될 때 업데이트되는 "internal hidden state"를 가지며, RNN block에서 나온 화살표가 다시 RNN으로 들어가는 구조입니다.
    * 즉 Recurrent neural network는 매 time step마다 $x$ 를 input으로 받아 network 내부의 "internal hidden state"를 특정 update formula를 통해 update해가며, 이를 통해 계산한 output $y$ 를 출력하며 동작합니다.
* hidden state는 RNN이 새로운 입력을 받을 때마다 매번 업데이트 되며, hidden state는 모델에 feedback되어 매 단계마다 $y$ 값을 출력하고, 이후에 또 다시 새로운 입력 $x$ 가 들어옵니다.
    1. RNN이 입력을 받습니다.
    2. "hidden state"를 업데이트합니다.
    3. 출력 값을 내보냅니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187445066-217cbf4f-71de-4356-b369-5a26d4f54c51.png">
</p>

* 위 그림은 RNN 모델을 펼쳤(unroll)을 때를 나타낸 것입니다.
* 각 timestep에서 RNN은 입력 프레임 $x_i$ 와 이전의 output(history) 두 개의 input을 가집니다.
* 모든 RNN block은 동일한 파라미터를 공유하지만, 각 timestamp에서 input과 history가 다른 동일한 block입니다.

<br>





# RNN hidden state update and output generation

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187332496-320e41e2-2ac0-44f3-8df0-d7cdace75a85.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187335442-fdeb659e-3693-4434-9388-5a940e5cbf00.png">
</p>

* 다음은 RNN을 수식으로 나타낸 것입니다.
    * $h_{t−1}$ : 이전 timestep(old state) $t−1$ 반복에서의 이전 상태, 즉 이전 상태의 hidden state
    * $x_t$ : 현재의 input vector
    * $f_W$ : 각 단일 timestep마다 적용되는 가중치 $W$ 를 가진 고정된 함수
        * 입력 또는 출력 시퀀스가 얼마나 길든, 매 단일 시간 단계에서 정확히 동일한 함수를 적용하기 때문에 시퀀스의 크기에 상관없이 시퀀스에서 순환 신경망을 사용할 수 있다.
    * $h_t$ : 현재 timestep(new state), 즉 다음 상태의 hidden state
    * $f_{W_{hy}}$ : output을 위한 함수
    * $y_t$ : output
* RNN에서의 hidden state는 가중치 행렬 $W$ 를 가지는 함수를 통해 위 슬라이드와 같이 계산합니다.
* 따라서, $t$ 에서의 hidden state는 ($t−1$ 에서의 state $h_{t−1}$)와 ($t$ 에서의 입력 벡터 $x_t$)를 입력으로 받아 가중치 행렬 $W$ 를 통해 계산하게 됩니다.
    * 이때 중요한 것은 함수는 모든 time step에서 $h_t$ 를 계산할 때 동일한 function과 $W$ 를 사용한다는 것입니다. 이는 어떠한 길이의 시퀀스라도 하나의 RNN으로 처리할 수 있다는 것을 의미합니다.
    * 즉 함수 $f$ 와 parameter $W$ 는 매 step마다 동일합니다.
* RNN에서 출력값 $y_t$ 를 가지려면 $h_t$​ 를 입력으로 하는 FC layer을 추가해야 합니다. FC layer은 매번 업데이트되는 $h_t$ 를 기반으로 출력 값을 결정합니다.

<br>





# (Vanilla) Recurrent Neural Network

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187337472-9556dbaa-e1da-415f-9dd0-b9f97b4f8a72.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187342133-5bd5d322-5d1a-431c-a991-9f915a6898d3.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187342135-1c322a02-7ee1-48e1-b09e-75a25d201607.png">
</p>

* 따라서, Vanilla RNN은 다음과 같이 계산합니다.
    * $t−1$ 에서의 이전의 hidden state($h_{t−1}$)와 $t$ 에서의 현재의 벡터($x_t$)를 입력으로 받습니다.
    * $h_{t−1}$ 와 $x_t$ 에 각각 가중치행렬 $W_{hh}$, $W_{xh}$ 를 곱하고 더해줍니다.
    * 앞에서 구한 값에 비선형함수(여기서는 tanh)를 취해 $t$ 에서의 현재의 hidden state인 $h_t$ 를 구합니다.
    * 마지막으로, 또 다른 가중치행렬 $W_{hy}$ 를 $h_t$ 에 곱한 결과를 $y_t$ 로, 즉 class score를 출력합니다.
* 그리고 푸는 문제에 따라서 Loss의 형태가 달라집니다.
    * Classification problem
        * $s = W_{hy} × h_t$
        * $Loss = Cross-entropy(s, y)$
    * Regression problem
        * $s = W_{hy} × h_t$
        * $Loss = ||s - y||^2_2$
* 즉, RNN 모델은 recurrence formula에 따라 세부적으로 다양한 종류의 모델들로 나뉘는데 그 중 가장 기본적인 모델인 Vanilla RNN의 $f_W$ 함수는 hidden state에 대해 선형변환을 하고, input vector에 대해서도 선형변환을 한 합에 nonlinear activation을 씌운 형태이며, 예측 단계에서는 해당 hidden state에 대해서 선형변환을 합니다.

<br>

정리하면, RNN 모델의 핵심은 시계열 데이터를 처리하기 위한 것입니다. 그래서 RNN 모델에서는 입력과 출력 말고도 순서 정보를 처리하기 위해 순서에 따라 업데이트되는 일종의 벡터인 internal state 혹은 hidden state를 가지고 있습니다. 그리고 RNN 모델에서는 데이터 상의 매 순서 혹은 시간마다 hidden state와 그 시간의 입력을 입력으로 받아 연산을 수행하는 recurrence formula를 통해서 새로운 순서 정보를 생성해냅니다.

<br>
<br>





# RNN Computational Graph

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187342892-6fc7d310-451f-4051-b647-38928647d29e.png">
</p>

* 이번에는 RNN의 formula를 Computational Graph로 살펴보겠습니다.
* 첫번째 input 데이터 $x_1$ 과 initial hidden state $h_0$ 이 필요합니다. $h_0$ 의 값은 보통 $0$ 으로 셋팅합니다.
* 이후에 $h_0$ 와 input $x_1$ 가 함수 $f_w$ 의 입력으로 들어가게 됩니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187344203-e564d977-d859-4617-b7c4-506bd06d40a2.png">
</p>

* 먼저, 초기 hidden state $h_0$ 와 input $x_1$ 을 함수 $f_w$ 의 입력으로 들어가서 새로운 hidden state $h_1$ 을 출력합니다.
* 그리고 다시 hidden state $h_1$ 과 다음 input $x_2$ 를 통해 $h_2$ 를 계산하고, $h_2$ 와 $x_3$ 를 통해 $h_3$ 를 계산하고, 이러한 과정을 반복합니다.
    * 즉 RNN이 hidden state를 가지며 이를 "재귀적으로" feed back 합니다.
* $h_t = f_W(h_{t-1}, x_t)$ : maximum length인 T까지 계속해서 같은 트렌드를 반복합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187345059-6ab4f4d5-8ef9-4475-8631-b4f54c23c243.png">
</p>

* 이때, 모든 time-step에서 동일한 함수, 동일한 가중치 행렬 $W$ 가 사용되기 때문에, Computational Graph에서도 하나의 노드를 통해 $W$ 를 위와 같이 나타낼 수 있으며, input으로 들어오는 sequence의 길이만큼 반복합니다.
    * 중요한 점은, 함수 $f_W$ 의 가중치 $W$ 는 각 step 마다 모두 동일한 값을 사용한다는 점입니다.
    * 즉, hidden state $h$ 와 input $x$ 는 매 step 바뀌지만 $W$ 는 매번 동일합니다.
    * 앞에서도 한번 언급했듯, 모든 time step in sequence에서 동일한 weight matrix $W$ 를 사용하기 때문에, 하나의 recurrent neural network에서 어떠한 길이의 시퀀스도 입력으로 받고 처리할 수 있으며, 위의 graph를 얼마나 반복해서 수행하느냐만 달라지게 됩니다.
* 이때 back porpagation 과정에서 weight matrix $W$ 도 $f_W$ 노드에 input 되어야 합니다.
    * 즉 $W$ 파라미터는 계속 같은 것을 사용하기 때문에, RNN 구조를 backpropagation 할 떄, 경로가 여러개가 생깁니다. 즉, 모든 경로에 대해 backprop을 진행하는데 copy gate로 볼 수 있으며, 이때 copy node를 지나면서 모든 경로(여기선 $f_w$)의 gradient를 더해주는 gradient adder로 볼 수 있습니다.
        * Gradient : 각 step에서 Weight에 대한 Gradient의 총합
        * Loss : 각 step에 구한 yt에 대한 Loss를 모두 더한 값
* 정리하면, 모든 time-step에서 동일한 함수, 동일한 가중치 행렬 $W$ 가 사용되기 때문에 입력으로 주어지는 데이터의 시간대의 길이와 무관하게 데이터를 처리할 수 있으며, 가중치 행렬 $W$ 에 대한 최종 loss는 각 step 에서 계산된 loss 값들의 합을 사용합니다.
* 따라서 backpropagation 과정에서 가중치 행렬 $W$ 를 gradient descent를 이용한 업데이트를 하려고 할때, $\frac{dL}{dW}$ 는 각 step 에서 $W$ 에 대한 local gradient의 합이 됩니다.

<br>





# RNN Sequential Task: Many to Many

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187356402-207c237a-8505-43b6-9dcc-99708f7e9a8f.png">
</p>

* 앞에서 살펴본 RNN을 이용한 여러가지 sequential task 중에서, many to many의 경우를 살펴보겠습니다.
* 각각의 선을 따라서 next hidden state node를 만들고, $y_t$ 를 지나서 loss를 계산하는 형태입니다.
* Many to many에서 입력과 출력의 길이가 같은 경우, 각 시점에 대해 일대일로 출력을 생성하는 Per-frame Video classification에 대한 전체 computational graph를 생각할 수 있습니다.
    * 각 frame 시점마다 출력이 나오게 되고, 이는 네트워크에서 predict한 class score 정보 이며, 이들 각각에 대한 Ground-truth label 대해 $y_t$ 와 Cross entropy Loss를 계산하게 됩니다. 즉, Sequence의 각 요소(시간)당 Loss $L_t$ 를 얻게 되는 것입니다.
    * 그리고 최종 Loss function은 모든 시점에 있었던 loss를 합산합니다. 그리고 이 final loss에 대해 back propagation을 수행합니다.
* 정리하면 다음과 같습니다.
    * many-to-many 모델에서 각 timestep마다 $y$ 를 출력하고 $L_1$, $L_2$, ..., $L_T$ 를 계산합니다.
    * 그리고 최종 loss $L$ 은 각 개별 loss의 합을 의미합니다.
    * 모델을 학습시키기 위해 역전파(backpropagation) 과정을 보면, loss는 각 timestep에서 이루어졌기 때문에 각 timestep마다 가중치 행렬 $w$ 에 대한 local gradient를 계산할 수 있습니다.
    * 따라서, 각각 계산된 local gradient를 최종 gradient에 더합니다.

<br>





# RNN Sequential Task: Many to One

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187356441-fc3381cc-4f2f-4495-86b1-2af3784e6b0d.png">
</p>

* 위 슬라이드는 시퀀스 입력을 받아서 하나의 출력을 내는 Many to one task에서의 Computational graph 입니다.
* many-to-one 경우에는 최종 hidden state $h_T$ 에 전체 시퀀스에 대한 정보를 가지고 있습니다.
* 이 경우는 전체 비디오 시퀀스에 대해 하나의 분류 레이블을 출력해야하는 Video Classificaiton으로 생각해볼 수 있으며, 여러 모델을 연결해서 최종의 hidden state에서 하나의 레이블을 출력하게 됩니다.
* 이때, 최종 hidden state는 전체 입력 시퀀스에 따라 영향을 받으므로, 네트워크가 마지막 classification을 수행하기 위해 순서대로 전체 시퀀스에서 알아야 하는 정보들을 encapsulate한 것이라고 볼 수 있습니다.

<br>





# RNN Sequential Task: One to Many

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187356471-9389058c-c525-460d-9f0a-7de0742dac83.png">
</p>

* 위 슬라이드는 One to many의 경우로 입력 벡터는 고정이지만 출력 벡터는 각각 변하며, Image captioning으로 생각해 볼 수 있습니다.
* 이 경우는 하나의 입력 $x$ 에서 recurrent한 관계들을 사용해 전체 출력 시퀀스를 생성하게 됩니다.
    * input $x$ 는 이미지 한 장, output은 예측한 sequences of words가 됩니다.
* 대게 고정 입력은 모델의 초기 hidden state를 초기화 시키는 용도로 사용합니다. 그리고 RNN은 모든 스텝에서 출력값을 가집니다.

<br>
<br>





# Sequence to Sequence: Many-to-one + one-to-many

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187363888-471d7541-b8c8-453b-85b3-ef44dd303616.png">
</p>

* Seq2seq는 Input과 output이 분리된 구조로, many to one과 one to many가 합쳐진 형태입니다.
    * 임의의 여러 개의 단어로 된 문장을 input으로 받아 다른 언어로 이루어진 임의의 여러 개의 단어로 된 문장을 ouput으로 생성해내는 machine translation이 이러한 구조를 가지며, 입력과 출력의 시퀀스 길이는 다를 수 있습니다.
* Seq2seq는 Encoder에 해당하는 many to one RNN과 Decoder에 해당하는 one to many RNN을 통해 구성하며 다음과 같은 방식으로 동작합니다.(영어를 한국어로 번역한다고 가정)
    * Encoder가 입력 시퀀스(영어문장)를 받아서 출력으로 최종 $h_T$ 를 내보냅니다. 이는 입력된 input sequence들이 summarize되어 업데이트 된 final hidden state라고 할 수 있습니다. 즉 가변입력을 하나의 벡터로 요약합니다.
        * 이를 컨텍스트 벡터(context vector)라 합니다.
    * Decoder는 이 hidden vector를 입력으로 받아서 시퀀스(한국어)를 출력합니다.
* 그림처럼 전체 계산그래프를 풀어서 전체 학습과정을 해석해보면, output sentence의 각 losses를 합해서 역전파를 진행합니다.

<br>
<br>





# Language Modeling

* RNN 구조는 자연어(natural language)를 만들어내는 language modeling 문제에서 유용하게 사용됩니다.
* characters level의 language modeling 이라면 매 step 마다 문자를, word level의 language modeling 이라면 매 step 마다 어떻게 단어를 생성해내어 완전한 문장을 만드는 것을 목표로 할 것입니다.
    * Language model의 기본 idea는 input data의 stream을 받아서 매 time point별 next character가 무엇인지 예측하는 것이며, 이를 통해 신경망이 문장의 글자 순서를 예측할 수 있기 때문에 Language Model이라고 부릅니다.
* language modeling의 간단한 예시를 위해 character(문자) level의 language model에 대해 살펴보겠습니다.
    * 간단한 예시로, 'h', 'e', 'l', 'o' 의 4가지 문자가 존재하고 이 문자들 (단어장) 을 이용해 'hell' 다음의 문자로 'o' 를 출력하려고 합니다.
    * 이를 위해서 RNN 에 모델에 'h', 'e', 'l', 'l' 을 순서대로 모델에 넣고, 각각의 step 에서의 해당 스텝의 다음 문자를 target character 로 하여 학습을 시켜야합니다.
    * 즉, 첫번째 input $x_1$ 'h' 가 RNN을 통과하여 output $y_1$ 값 'e' 가 나와야하고, 다음 input $x_2$ 'e' 가 RNN을 통과하여 output $y_2$ 'l' 이 나와야합니다.

<br>





# Train time

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187371210-66ee4bc1-ae3a-4243-bf27-a251b930b848.png">
</p>

* training 과정을 살펴보는데, 첫 번째 예시는 Character Prediction 문제 입니다. 이는 문장 채우기를 many to many로 풀어냅니다.
* 'H' 를 입력하면 'HELLO' 가 자동완성 되도록 하는 상황을 생각해보겠습니다.
    * input sequence : 'h', 'e', 'l', 'l'
    * output sequence : 'e', 'l', 'l', 'o'
* 우선 위 그림처럼 input sequence를 'h', 'e', 'l'과 같이 미리 정해놓은 vocabulary를 one-hot encoding 시킨 vector로 변환시킵니다.
    * h = [1, 0, 0, 0]
    * e = [0, 1, 0, 0]
    * l = [0, 0, 1, 0]
    * o = [0, 0, 0, 1]

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187371237-d407f870-95da-4004-9449-722fa3184574.png">
</p>

* $h_0 = 0$ 이라고 가정하고, $h_t$ 들을 구하는 식을 연산할 수 있습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187371275-a1cf6899-0dce-4585-8a06-a4226aaaadca.png">
</p>

* 여기까지 한 번의 forward pass step 입니다.
* 이러한 sequence of input vector를 통해 time step별 hidden state를 구하고 각 단어에 대한 예측결과로 output을 출력해줍니다. 이렇게 network는 매 time point별 next element in the sequence (다음 올 단어)를 예측하게 됩니다.
* 타겟은 각각 'e', 'l', 'l', 'o'이지만, predicted score를 보면 각각 'o', 'o', 'l', 'o' 입니다.
    * 즉, $s_1$, $s_2$ 는 틀렸고, $s_3$, $s_4$ 는 맞았습니다.
    * $s_1 = W_{hy} × h_1$
    * $s_2 = W_{hy} × h_2$
    * $s_3 = W_{hy} × h_3$
    * $s_4 = W_{hy} × h_4$
* True $y_1$, $y_2$, $y_3$, $y_4$ 와 비교해서 각각의 cross-entropy loss를 계산한 후, 전체 loss를 계산합니다. 그리고 이를 최소화하는 가중치 $W$ 를 찾는 train 과정이 필요합니다.
    * $L_1 = loss(s_1, y_1)$
    * $L_2 = loss(s_2, y_2)$
    * $L_3 = loss(s_3, y_3)$
    * $L_4 = loss(s_4, y_4)$
* 정리하면 "hello"를 학습한다고 할때, 이 모델을 구성하기 위해서는 다음과 같은 순서를 따릅니다.
    * 신경망의 입력으로 넣어주기 위해, 각 문자를 하나의 one-hot vector로 변환합니다.(위 슬라이드의 붉은색 박스)
    * 입력을 받아서 hidden state sequence를 생성합니다.(위 슬라이드의 초록색 박스)
    * 각 단어에 대한 예측 결과를 출력합니다.(위 슬라이드의 파란색 박스)

<br>
<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187375681-ee6d4588-2b72-48e5-8a2e-e66f697b913f.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187375717-ceff1ac6-b124-46e0-a898-1a4d8ce28c35.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187375744-4b728055-cd16-4702-afd3-77e8e2dea74c.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187375768-a6750946-7f19-4462-862b-fd48e2e2fa1c.png">
</p>

* 위 4개의 슬라이드는 어떠한 입력을 받아서 어떠한 출력을 하도록 학습하는지를 보여줍니다.
    * "h" 입력 —> "e"를 출력하도록 학습
    * "h", "e"를 입력 —> "l"을 출력하도록 학습
    * "h", "e", "l"을 입력 —> "l"을 출력하도록 학습
    * "h", "e", "l", "l"을 입력 —> "o"를 출력하도록 학습
* Forward pass관점에서는 RNN 구조 특성상 이전 input들이 모두 반영되어 예측에 활용됩니다.
* Backward pass관점에서는 반대로 여러 경로들(활용한 input 노드 수만큼)로 W의 그래디언트를 계산하게 됩니다.

<br>





# Test time

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187380713-0521ddc7-2c9b-4749-ad3d-58298527de4e.png">
</p>

* Test time때, 학습된 모델은 initial seed token이 되는 단어 하나를 입력받아서 위 슬라이드와 같은 방식으로 새로운 텍스트를 생성할 수 있습니다.
    * Predict한 결과를 다시 입력에 input 시킴으로써 한 글자만 입력해도 여러 글자를 예측 할 수 있습니다.
* 위의 예시에서 모델에 'h' 가 입력되면 output으로 모든 문자 'h', 'e', 'l', 'o' 애 대한 score 벡터를 얻을 수 있습니다.
    * 이 score 들을 softmax 함수를 이용해서 각각을 확률 값으로 나타내고, 확률 분포에 따라 하나의 문자를 샘플링하여 one-hot endcoding 후 다음 input으로 들어가게 됩니다.
    * 이렇게 학습시킨 모델을 활용할 수 있는 방법들 중 하나는 model로부터 sampling하는 것입니다.
* 이때, 가장 높은 score의 문자를 사용하는 것이 아니라 확률 분포에 따라 샘플링하는 이유는 모델의 다양성(diversity)을 얻기 위함입니다.
    * 즉 전체 문장을 만들어내기 위해 타임 스텝마다 확률 분포에서 문자를 하나씩 뽑아냅니다.
* 그렇다면 이전 step 에서 얻은 확률 분포 벡터를 다음 step의 input으로 그대로 사용하면 될 거 같다는 생각이 드는데, 굳이 하나의 문자만을 샘플링해 one-hot encoding을 하는 이유는 무엇일까?
    * 첫번째 이유는 train time 에서 모델이 모든 input이 one-hot encoding 된 상태로 학습이 되었기 때문에 다른 형태의 input이 들어갔을때 모델의 성능이 저하될 수 있습니다.
    * 두번째 이유는 위의 예시에서는 단 4개의 문자로 이루어진 vocabulary를 사용해 길이가 4인 벡터가 input, output 으로 사용됐지만, 사실 우리가 쓰는 언어에서 단어는 엄청나게 많기 때문에 그렇게 많은 차원을 가지는 softmax vector(dense vector)를 사용하려면 연산량이 엄청나게 많습니다. 따라서 one-hot endcoding을 이용한 sparse vector를 사용합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187396716-c0b24798-a927-4e2b-9e82-75b7fa8a6883.png">
</p>

* hidden state 계산에서 입력(여기서는 one-hot vector)이 가중치 행렬 W와 곱해지는 경우를 생각해보면, 이 곱셈 연산은 아주 sparse하다는 것을 알 수 있습니다.
* 위 슬라이드에서 알 수 있듯이, $W$ 에서 한개의 column만을 추출하면 되기 때문에 단순히 열을 추출하는 방식으로 구현하는 것이 더 효율적입니다.
    * 즉 $W$ 에 원-핫 인코딩으로 생성된 $x$ 를 곱하는 행위는 곧 $W$ matrix에서 특정 열을 선택해서 추출하는 것과 같습니다.
    * 이 때 특정 열은 input 벡터 $x$ 에서 1값을 갖는 행입니다.
        * $w_{11}$, $w_{21}$, $w_{31}$


<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187396746-f72b45e8-6fbc-4f13-b2c6-f6b187edaab4.png">
</p>

* 이러한 이유로 인해, 일반적으로 위 슬라이드와 같이 입력과 RNN사이에 Embedding layer(노란색 박스)라는 것을 추가해줍니다.
* Embedding layer는 one-hot vector가 $W$ 의 어떤 column에 해당하는지를 학습하게 됩니다. 이는 단어를 sparse한 one-hot vector가 아닌 dense vector로 만들어주어 저차원에서 더 많은 단어를 표현할 수 있게 됩니다.

<br>
<br>





# Truncated Backpropagation Through Time

<p align="center">
<img alt="image" src="">
</p>

* RNN 모델의 train 시에 loss를 구할때 각 step에서 나온 loss를 모두 합해서 최종 loss를 구했습니다.
    * 즉, 전체 seqence에 대해 forward pass를 진행하여 모든 step의 loss를 더해 최종 loss를 구하고 이것을 이용하여 backpropation을 진행합니다.
* 하지만 이러한 방법은 seqence 가 아주 긴 경우에는 문제가 발생할 수 있습니다.
    * 예를 들어, wikipedia 전체 문서를 학습시키려고 하면, 하나의 학습 step 마다 전체 wikipedia 문서를 거쳐 forward pass를 진행하고 gradient를 구할 수 있습니다. 이런 경우 연산량이 굉장히 많고 학습이 굉장히 느리게 진행될 것입니다.
    * 설령 Forward pass 계산시에도 연산 가능하다하더라도, Backward pass할 때 메모리의 문제가 큽니다.
        * $W$ 에 대한 그래디언트 계산을 위해서는 수많은 computational graph가 모두 살아있어야하며, 수많은 경로가 존재하기 떄문입니다.
* 즉 RNN에서의 역전파는 위 슬라이드와 같이 아주 긴 시퀀스를 학습하려고 할 때, 엄청난 양의 메모리가 필요하다는 문제가 있습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187432379-4bc97faf-c812-483d-8d79-fcc955809404.png">
</p>

* 따라서, 아주 긴 시퀀스를 RNN으로 처리하는 경우에는 대체 근사 알고리즘(alternative approxtimate algorithm)을 사용합니다.
    * "Truncated Backpropagation" 이라는 방법을 사용합니다.
    * RNN 버전의 mini-batch gradient descent 이라고 생각하면 됩니다.
* 메모리 로드를 막기 위한 practical한 방법인 Truncated backpropagation 방법은, train time에 한 스텝을, sequences를 일정 단위(batch)로 나누고 batch 만큼만 forward pass를 진행합니다. 그리고 batch seqence의 loss를 계산하여 gradient descent를 진행합니다.
    * 예를 들어 한 문단(chunks of the sequence)에서 자릅니다. Forward pass와 backward pass를 진행하여 $W$ 를 업데이트하고, $h_T$ hidden state를 만듭니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187432418-932f10be-c9e6-4d22-b177-be1d2884b4ac.png">
</p>

* 다음으로, 이전 batch 에서의 hidden state를 받아 다음 batch 에서도 동일한 과정을 진행합니다.
    * 앞에서 나온 $h_T$ 를 가지고 다음 input 벡터들과 함께 hidden state를 만들어고, forward pass, backward pass를 진행하여 $W$ 를 업데이트 합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187432433-e2d693f5-6e70-4ef7-99f3-7f572b2e9570.png">
</p>

* 이는 전체 시퀀스를 나누어서 학습하는 방법으로, 동작 방법을 정리하겠습니다.
    * 1번째 chunk의 시퀀스에서 모든 hidden state를 계산해 loss를 구하고, 1번째 chunk의 시퀀스에 대해서만 backprop을 통해 $W$ 를 학습시킵니다.
    * 그리고 1번째 chunk의 마지막 hidden state 값을 기록해뒀다가 2번째 chunk로 전달합니다.
    * hidden state값을 전달받은 2번째 chunk는, 다시 2번째 chunk의 시퀀스에 대해서 모든 hidden state와 loss를 계산하고 2번째 chunk의 시퀀스에 대해서만 backprop을 수행합니다.
    * 그리고 2번째 chunk의 마지막 hidden state 값을 기록해뒀다가 3번째 chunk로 전달합니다.
    * 이러한 과정을 끝까지 반복해서 수행합니다.
* 정리하자면, 위 그림처럼 전체 seqeunce를 학습하지 않고 sequence의 subset(chunk)으로 나누어 학습시키는 방식으로 각 chunk별 마지막 hidden state만 기억하여 다음 chunk로 전달하는 방식입니다.
* 위와 같이, 각 chunk에 대해서만 backprop을 수행하면서 학습하기 때문에 이 방법을 "Truncated Backpropagation" 라고 부르며, 각 chunk에 대한 정보만 저장하면 되므로 한정된 자원의 GPU에서도 학습을 수행할 수 있게 됩니다.
    * 결국 각 chunk별 loss를 통해 해당 chunk의 weight matrix를 학습하는 형태가 되는 것입니다.

<br>
<br>





# Example: Character generation

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187439888-045deade-8c89-4ca6-81fd-3215ccb1b247.png">
</p>

* RNN language model 을 활용하여 여러가지 데이터들을 학습시켜 재밌는 결과들을 얻을 수 있습니다.
* 셰익스피어의 작품들을 RNN으로 학습시켜 볼 수 있습니다.
* 셰익스피어의 소설을 input으로 통째로 집어넣습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187439910-b2fe8300-4fba-4155-bc21-7327afd670b7.png">
</p>

* 학습 초기에는 모델이 의미없는 문장들만 뱉어내지만, 학습을 시키면 시킬수록 의미있는 문장을 만들어냅니다.
* 훈련을 계속 진행하면서 어느정도 문장의 형태를 갖춘 문자로 나옵니다. 영어 문법을 잘 지키지않으면 말이 안되는 문장을 반환합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187439927-1d1e358e-80b2-4152-bca7-751cc3c4ae88.png">
</p>

* 마지막 결과를 보면, 그럴듯한 결과를 생성해 낸다는 것을 알 수 있습니다.
* 학습을 많이 시키면 훨씬 더 긴 문장들도 만들어낼 수 있으며, 모델이 HEAD에 발화자를 넣어야한다는 것을 알고, 셰익스피어풍의 문장들을 만들어냅니다. 다른 문장을 시작할 때 한 줄을 비워야 하는 것도 압니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187441900-3db76c76-73fe-40be-9c80-0db4256ffa45.png">
</p>

* 이번에는 단순한 문장이 아니라 어려운 수식들이 포함된 수학책을 학습시켜봅니다.
* 수학책의 수식이 LaTex 문법으로 작성되어 있으며, 교과서의 LaTex 코드를 우리가 만든 RNN Language Model로 학습시킬 수 있습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187442029-55fe0596-05fd-443f-8443-98d2e104d879.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187441979-faa5f416-2b8c-418b-97e7-ab1e937c34bf.png">
</p>

* 위와 같이 수학 교과서의 공식, 다이어그램과 같은 전체 구조를 학습하는 것을 확인할 수 있습니다.
* 수학적으로 봤을때 말도안되는 형태이지만 위 그림처럼 diagram도 표현하고 증명도 서술되며 그럴듯한 형태로 나타내고 있습니다.
* 재미있는 점 중 하나는 모델이 "증명 생략" 도 학습합니다.(ㅋㅋ?)

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187443038-e99e3ea4-618b-43ad-ae80-468d51018bc3.png">
</p>

* 이번엔 리눅스 커널 소스코드를 학습시켜봅니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187443063-e03dabb7-c540-4843-b7b2-8cc1fc3ce390.png">
</p>

* 학습된 모델에서 샘플링을 해보면 C 소스코드 스러운 것들이 나옵니다.
* 모델이 if 문 작성법을 알고 있고, 들여쓰기와 중괄호를 쓰는법도 잘 알고있고, 주석다는 법도 알고있습니다.
* 물론 뜻은 아무 의미도 없습니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/187443096-4914c5e9-248a-41fe-804a-789c7cbcb388.png">
</p>

* 심지어 소스코드 제일 위에 GNU license 저작권까지 표기했습니다.
* 정리하면 모델은 데이터의 일반적인 구조를 아주 잘 학습했습니다.

여기서 중요한 점은 우리는 RNN 모델을 통해 다음의 단어가 올 것만을 학습시켰고, 모델에게 요청한 것은 그저 시퀀스의 다음 문자를 예측하라는 것이었는데, 구조에 대해서는 전혀 말해주지 않았음에도 불구하고 모델이 알아서 전체 구조에 대해 학습했다는 점입니다.
* 즉 모델은 학습과정 동안에 시퀀스 데이터의 숨겨진 구조(latent structure)를 알아서 학습합니다.

<br>
<br>
