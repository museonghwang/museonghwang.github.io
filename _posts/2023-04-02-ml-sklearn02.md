---
layout: post
title: Scikit-Learn 기반 프레임워크
category: Machine Learning
tag: Machine-Learning
---

 


## Estimator 이해 및 fit(), predict() 메서드

사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 엿보이는 패키지입니다. 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 ML 모델 학습을 위해서 **fit()** 을, 학습된 모델의 예측을 위해 **predict()** 메서드를 이용하여 간단하게 학습과 예측 결과를 반환합니다.

사이킷런은 Estimator라고 하는 수십가지 머신러닝 알고리즘과 모델을 제공합니다. 데이터셋을 기반으로 일련의 모델 파라미터들을 추정하는 객체를 Estimator라고 합니다. 당연히 `Estimator` 클래스는 `fit()` 과 `predict()` 를 내부에서 구현하고 있습니다.

<br>
<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/234798109-ecb75354-b980-4371-8255-dca9a58ac8ee.png">
</p>

<br>




## 사이킷런의 주요 모듈

다음은 사이킷런의 주요 모듈을 요약한 것입니다. 많은 모듈이 있으나 자주 쓰이는 핵심 모듈 위주로 정리한 것입니다.

| 분류 | 모듈명 | 설명 |
| --- | --- | --- |
| 예제 데이터&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | **sklearn.datasets** | 사이킷런에 내장되어 예제로 제공하는 데이터 세트 |
| 피처 처리 | **sklearn.preprocessing** | 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링 등) |
| - | **sklearn.feature_selection** | 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공 |
| - | **sklearn.feature_extraction** | 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨. 예를 들어 텍스트 데이터에서 Count Vectorizer Tf-Idf Vectorizer 등을 생성하는 기능 제공. 텍스트 데이터의 피처 추출은 sklearn.feature_extraction.text 모듈에, 이미지 데이터의 피처 추출은 sklearn.feature_extraction.image 모듈에 지원 API가 있음. |
| 피처 처리 & 차원 축소 | **sklearn.decomposition** | 차원 축소와 관련한 알고리즘을 지원하는 모듈임. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능을 수행할 수 있음 |
| 데이터 분리, 검증 & 파라미터 튜닝 | **sklearn.model_selection** | 교차 검증을 위한 학습용/테스트용 분리, 그리드 서치(Grid Search)로 최적 파라미터 추출 등의 API 제공 |
| 평가 | **sklearn.metrics** | 분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법 제공. Accuracy, Precision, Recall, ROC-AUC, RMSE 등 제공 |
| ML 알고리즘 | **sklearn.ensemble** | 앙상블 알고리즘 제공. 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등을 제공 |
| - | **sklearn.linear_model** | 주로 선형 회귀, 릿지(Ridge), 라쏘(Lasso) 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원. 또한 SGD(Stochastic Gradient Descent) 관련 알고리즘도 제공 |
| - | **sklearn.naive_bayes** | 나이브 베이즈 알고리즘 제공. 가우시안 NB, 다항 분포 NB 등. |
| - | **sklearn.neighbors** | 최근접 이웃 알고리즘 제공, K-NN 등 |
| - | **sklearn.svm** | 서포트 벡터 머신 알고리즘 제공 |
| - | **sklearn.tree** | 의사 결정 트리 알고리즘 제공 |
| - | **sklearn.cluster** | 비지도 클러스터링 알고리즘 제공. (K-평균, 계층형, DBSCAN 등) |
| 유틸리티 | **sklearn.pipeline** | 피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공 |


일반적으로 **<span style="color:red">머신러닝 모델을 구축하는 주요 프로세스</span>** 는 **피처의 가공, 변경, 추출을 수행하는 피처 처리(feature processing), ML 알고리즘 학습/예측 수행, 그리고 모델 평가의 단계를 반복적으로 수행하는 것** 입니다. 사이킷런 패키지는 머신러닝 모델을 구축하는 주요 프로세스를 지원하기 위해 매우 편리하고 다양하며 유연한 모듈을 지원합니다. 이러한 편리성, 다양성, 유연성이 바로 많은 ML 개발자가 사이킷런 파이썬 기반의 ML 개발 프레임워크로 선택하게 된 이유일 것입니다.



## 내장된 예제 데이터 세트

사이킷런에는 예제로 활용할 수 있는 간단하면서도 좋은 데이터 세트가 내장돼 있습니다. 이 데이터는 **datasets** 모듈에 있는 여러 API를 호출하여 사용할 수 있습니다. 사이킷런에 내장 되어 있는 데이터 세트는 분류나 회귀를 연습하기 위한 **예제용도의 데이터 세트** 와 분류나 클러스터링을 위해 **표본 데이터로 생성될 수 있는 데이터 세트** 로 나뉘어집니다.



### 분류 회귀 연습용 예제 데이터

| API 명 | 설명 |
| --- | --- |
| **datasets.load_boston()** | 회귀 용도이며, 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트 |
| **datasets.load_breast_cancer()** | 분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트 |
| **datasets.load_diabetes()** | 회귀 용도이며, 당뇨 데이터 세트 |
| **datasets.load_digits()** | 분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트 |
| **datasets.load_iris()** | 분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트 |


**fetch** 계열의 명령은 데이터의 크기가 커서 패키지에 처음부터 저장돼 있지 않고 인터넷에서 내려받아 홈 디렉터리 아래의 **scikit_learn_data** 라는 서브 디렉터리에 저장한 후 추후 불러들이는 데이터입니다.

- **fetch_covtype()**: 회귀 분석용 토지 조사 자료
- **fetch_20newsgroups()**: 뉴스 그룹 텍스트 자료
- **fetch_olivetti_faces()**: 얼굴 이미지 자료
- **fetch_lfw_people()**: 얼굴 이미지 자료
- **fetch_1fw_pairs()**: 얼굴 이미지 자료
- **fetch_rcv1()**: 로이터 뉴스 말뭉치
- **fetch_mldata()**: ML 웹사이트에서 다운로드



### 분류와 클러스터링을 위한 표본 데이터 생성기

| API 명 | 설명 |
| --- | --- |
| **datasets.make_classifications()** | 분류를 위한 데이터 세트를 만듭니다. 특히 높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성해 줍니다. |
| **datasets.make_blobs()** | 클러스터링을 위한 데이터 세트를 무작위로 생성해 줍니다. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 세트를 쉽게 만들어 줍니다. |

표본 데이터 생성기는 이 밖에도 많으며, 위의 2개 정도로도 여러 가지 사례에 사용할 수 있습니다.

분류나 회귀를 위한 연습용 예제 데이터가 어떻게 구성돼 있는지 좀 더 살펴보겠습니다. 사이킷런 내장된 이 데이터 세트는 일반적으로 딕셔너리 형태로 돼 있습니다.

키는 보통 **data**, **target**, **target_name**, **feature_names**, **DESCR** 로 구성돼 있습니다. 개별 키가 가리키는 데이터 세트의 의미는 다음과 같습니다.

- **data**: 피처의 데이터 세트를 가리킵니다.
- **target**: 분류 시 레이블 값, 회귀일 때는 숫자 결과값 데이터 세트입니다.
- **target_names**: 개별 레이블의 이름을 나타냅니다.
- **feature_names**: 피처의 이름을 나타냅니다.
- **DESCR**: 데이터 세트에 대한 설명과 각 피처의 설명을 나타냅니다.

**data**, **target** 은 넘파이 배열(ndarray) 타입이며, **target_names**, **feature_names** 는 넘파이 배열 또는 파이썬 리스트(list) 타입니다. **DESCR** 은 스트링 타입입니다. 먼저 붓꽃 데이터 세트를 생성해 보겠습니다.
```py
from sklearn.datasets import load_iris

iris_data = load_iris()
print(type(iris_data))

[output]
<class 'sklearn.utils._bunch.Bunch'>
```

<br>

**load_iris()** API의 반환 결과는 **sklearn.utils.Bunch** 클래스입니다. **Bunch** 클래스는 파이썬 딕셔너리 자료형과 유사합니다. 데이터 세트에 내장돼 있는 대부분의 데이터 세트는 이와 같이 딕셔너리 형태의 값을 반환합니다. 딕셔너리 형태이므로 **load_iris()** 데이터 세트의 **key값** 을 확인해 보겠습니다.
```py
keys = iris_data.keys()
print('붓꽃 데이터 세트의 키들:', keys)

[output]
붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])
```

<br>

다음 그림에서 **load_iris()** 가 반환하는 붓꽃 데이터 세트의 각 키가 의미하는 값을 표시했습니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/235042347-1c8e5f3b-389b-470e-8dff-b7be04b3a480.png">
</p>

<br>

**load_iris()** 가 반환하는 객체의 키들이 가리키는 값을 다음 예제 코드에 출력했습니다.
```py
print('feature_names 의 type:', type(iris_data.feature_names))
print('feature_names 의 shape:', len(iris_data.feature_names))
print(iris_data.feature_names)

print('\ntarget_names 의 type:', type(iris_data.target_names))
print('feature_names 의 shape:', len(iris_data.target_names))
print(iris_data.target_names)

print('\ndata 의 type:', type(iris_data.data))
print('data 의 shape:', iris_data.data.shape)
print(iris_data['data'])

print('\ntarget 의 type:', type(iris_data.target))
print('target 의 shape:', iris_data.target.shape)
print(iris_data.target)

[output]
feature_names 의 type: <class 'list'>
feature_names 의 shape: 4
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']

target_names 의 type: <class 'numpy.ndarray'>
feature_names 의 shape: 3
['setosa' 'versicolor' 'virginica']

data 의 type: <class 'numpy.ndarray'>
data 의 shape: (150, 4)
[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 ...
 [6.2 3.4 5.4 2.3]
 [5.9 3.  5.1 1.8]]

target 의 type: <class 'numpy.ndarray'>
target 의 shape: (150,)
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]
```











