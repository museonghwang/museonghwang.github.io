---
layout: post
title: CS231n Lecture7 Review
category: CS231n
tag: CS231n
---

해당 게시물은 [Standford 2017 CS231n](http://cs231n.stanford.edu/2017/syllabus.html) 강의와 2022년 슬라이드를 바탕으로 작성되었습니다.




<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185549686-4216e74e-998d-4f5c-852b-d74283a10cc5.png">
</p>

<br>





## Last time: Activation Functions

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185551956-31338de7-ba7b-4993-af42-6e23e8e9c684.png">
</p>

* 지난시간에 Nerural networks를 학습 시킬 때 필요한 여러가지 중요한 것들을 배웠습니다.
* 다양한 Activation Function과 각각의 특성이 존재했는데, 과거에는 sigmoid를 썼지만 Gradients Vanishing 문제때문에 요즘은 대부분 ReLU를 씁니다.

<br>

## Last time: Weight Initialization

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185551978-1505b59d-9085-4fe9-a9b6-7711a8fe75a0.png">
</p>

* 가중치 초기화에 대해서도 배웠습니다.
    * 가중치가 지나치게 작으면 activation이 사라지는데, 작은 값이 여러 번 곱해지기 때문에 점점 0이 되어, 결국 모든 값이 0이 되고 학습은 일어나지 않습니다.
    * 반면에 가중치가 너무 큰 값으로 초기화되면 그 값이 또 계속 곱해질 것이고 결국은 폭발합니다. 이 경우에도 학습이 일어나지 않을 것입니다.
* Xavier/MSRA(HE) Initialzation 같은 방법으로 초기화를 잘 시켜주면 Activation의 분포를 좋게 유지시킬 수 있습니다.
* 특히 Network가 깊어지면 깊어질수록 가중치를 더 많이 곱하게 되기 때문에 가중치 초기화와 활성함수는 더 중요합니다.

<br>

## Last time: Data Preprocessing

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185551995-9a14cbb2-2c81-48c8-a5df-fcb07cbf12fd.png">
</p>

* image data는 주로 zero-mean을 주로 사용합니다.

<br>

##  Last time: Data Preprocessing

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185552019-ac6538d6-73f1-4d97-8076-d8d7f94c66fd.png">
</p>

* 왜 normalization가 중요한지에 대한 직관
* Linear Binary classification 문제(빨간/파란 점들을 나누는 것)를 푼다고 가정하겠습니다.
    * 왼쪽
        * not normalized/centered data 입니다.
        * classification 자체는 가능하지만, 선이 조금만 움직여도 classification이 잘 되지 않습니다.
        * 즉, 손실 함수가 아주 약간의 가중치 변화에도 엄청 예민합니다.
        * Loss가 파라미터에 너무 민감하기 때문에, 동일한 함수를 쓰더라도 학습 시키기 아주 어렵습니다.
    * 오른쪽
        * zero-center data, Unit variance로 만들어 준 경우 입니다.
        * 선이 조금만 움직여도 손실 함수는 이런 가중치의 변동에 덜 민감합니다.
        * 이 경우 최적화가 더 쉬우며, 학습이 더 잘됩니다.

normalization은 Linear classification의 경우에만 국한되는 것이 아니라, Neural network 내부에도 다수의(interleavings) linear classifer가 있다고 생각할 수 있는데, 이 경우 Neural network의 입력이 zero-centered가 아니고 Unit variance가 아닌 경우라면 레이어의 Weight matrix가 아주 조금만 변해도 출력은 엄청 심하게 변하게 됩니다. 이는 학습을 어렵게 합니다.

<br>

## Last time: Batch Normalization

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185552041-6a9e0aaa-445f-4a61-adb6-8bb21c5c332e.png">
</p>

* Normalization이 엄청 중요하다는 것을 알고있기 때문에, batch normalization도 배웠습니다.
* activations이 zero mean과 unit variance가 될 수 있도록 레이어를 하나 추가하는 방법이었습니다.
    * forward pass 시에 미니배치에서의 평균과 표준편차를 계산해서 Normalization을 수행했습니다.
    * 그리고 레이어의 유연한 표현성(expressivity)을 위해서 scale, shift 파라미터를 추가했습니다.

<br>

## Last time: Babysitting Learning

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185552057-dee94ad9-f572-4ddb-b8a6-7eed9b670472.png">
</p>

* 학습 과정(Loss curve가 어떻게 보여야 하는지)을 다루는 방법도 배웠습니다.
* 위 슬라이드를 해석해보면 Training set의 성능을 계속 올라가며 Loss는 계속 내려갑니다. 하지만 validation은 침체하고 있습니다.
    * 위 상황은 overfititing.
    * 추가적인 regularization이 필요합니다.

<br>

## Last time: Hyperparameter Search

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185552070-ccc79b32-f6df-4e4a-ae26-52066b4bb1a6.png">
</p>

* hyperparameter search도 배웠습니다.
* 네트워크에는 무수히 많은 하이퍼파라미터가 존재하며, 이를 올바르게 잘 선택하는 것은 상당히 중요합니다.
* grid search와 random search를 배웠으며, 이론상 random search가 더 좋았습니다.
    * 왜냐하면 성능이 특정 하이퍼파라미터에 의해 크게 좌우될 때 그 파라미터를 좀 더 넓은 범위로 탐색할 수 있기 때문입니다.
* 그리고 하이퍼파라미터 최적화 시에 coarse search 이후 fine search를 합니다.
    * coarse search
        * 처음에는 하이퍼파라미터를 가능한 최대한 넓은 범위를 설정해서 찾습니다.
        * 그 범위가 하이퍼파라미터 범위의 끝에서 끝까지 다 살펴볼 수 있도록 할수록 좋습니다.
        * Interation도 작게 줘서 학습시켜봅니다.
        * 그리고 결과가 좋은 범위로 좁히는 것입니다.
    * fine search
        * iterations를 조금 더 돌면서 더 작은 범위를 다시 탐색합니다.
    * 적절한 하이퍼파라미터를 찾을 때 까지 이 과정을 반복합니다.

<br>
<br>





# Gradient descent for optimization

* Fancier optimization을 살펴보기전에 Gradient descent를 다시 짚어보고, 문제점을 살펴보겠습니다.
* 이전에 Loss function에 대한 정의 및 역할이 제시되었습니다.
    * 최적의 $W$ 를 찾아서 classifier가 이미지들을 잘 분류하고 있는지 검사를 해야하는데, 즉, $W$ (weight)가 좋은지 아닌지 정량화 할 수 있는 기준이 필요했기에 Loss function이 등장했습니다.
    * 손실 함수(Loss Function)는 현재 분류기(classifier)가 얼마나 좋은지를 알려줍니다. 다르게 표현하면 현재의 $W$ 가 얼마나 BADNESS한지 를 알려주는 것입니다.
* 기존의 Loss function은 문제점을 가지고 있었습니다.
    * training data에 대해 좋은 성능을 만들려고 합니다.
    * 하지만 우리가 원하는것은 test data에 대한 일반화입니다.
* 이러한 문제점은 Overfiiting으로 이어집니다.
    * 즉 모델이 training data에 대해서만 잘 수행하고, unseen data에 대해 낮은 성능을 보이는 현상입니다.
* Overfitting을 방지하기 위해 Data loss term에 Regularization term을 추가하였습니다.
    * 즉, Simpler Models을 선호하게 하여 Overfit을 방지합니다.
    * 일반적으로 L2 regularization를 사용합니다.
    * 더 복잡한 regularization은 Dropout, Batch normalization, Cutout, Mixup, Stochastic depth 등등 여러가지 방법론이 존재합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185561594-c01cd0d8-1446-4d92-8c33-72bdc54cd8b9.png">
</p>

정리하면, nice(좋은)한 $W$를 찾기 위한 Loss function은 training data에 맞는 Data Loss과 Overfitting을 방지하기 위한 regularization으로 구성됩니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185562463-2a0fcbf4-25f7-4388-a206-4907b45b1170.png">
</p>

* 그리고 최종적으로 $L(W)$ 함숫값을 최소화하는 최적의 W를 구하는 것이 목적입니다.
* 따라서, 최적의 $W$ 는 $W^*\ =\ argmin_wL(W)$ 의 식으로 구합니다.
    * argmin : minimizer
    * $L(W)$를 최솟값으로 만드는 $W$를 $W*$로 정의합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185564759-f0057690-67e6-462e-b05d-eadddf98ef36.png">
</p>

* 그렇다면 이 $W_*$ 를 어떻게 찾을까?
    * 최적의 $W$ 값을 찾기는 어렵습니다. 하지만 찾고자 하는 방법으로 2가지가 있습니다.
        1. Random search
        2. slope를 따라내려가는 방법
    * Random search는 랜덤으로 $W$ 값의 후보를 정해서 함숫값을 구하는데, 즉, 매번 $W$ 를 조금씩 개선시켜 loss를 낮추고자 하는 것입니다.
        * 좋은 방법이 절대 아니며, 성능또한 좋지 않고, 차원의 저주에 빠질 수 있습니다.
* 위 질문은 gradient descent로 이어집니다.
    * $L(W)$ 는 주로 전체 개형을 알 수 있는 함수가 아닙니다.
    * 개형은 알지 못하고, $W=W0$ 이라는 점이 주어졌을 때 그 근접한 곳만 알 수 있습니다.
    * 여기서 할 수 있는 방법으로 slope를 따라내려가는 방법이 있습니다.
        * 경사를 따라내려가는 방법은 곧 함수에서의 derivative(미분)를 따라가는 것입니다.
        * 그래디언트의 기하학적 의미: 그래디언트 방향은 함수가 가장 증가하는 방향.
        * 다르게 이야기하면, 그 점에서 loss function이 가장 감소할 수 있는 방향을 의미하며, 따라서 negative gradient의 방향으로 점점 가면 최소점에 도달할 것 입니다.
* 그렇다면 함수의 개형을 알지 못하는 상황에서 어디가 최적점인지 어떻게 알 수 있을까?
    * 그냥 내려가봐야 합니다.
    * 그래디언트를 구해서 함수가 감소하는 방향으로 가는 것이 절대 전체적인 최적의 global minimum으로 가는 것을 보장하지는 않습니다.
    * 즉, 전체 shape에 대해 전혀 알지 못하지만, 내리막길을 따라가면 낮은 곳으로 가게 될 것이라고 믿습니다.(최적점인지에 대한 확신은 없습니다.)

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185565010-27a61b90-ef56-4394-8463-8bcc1e40793f.png">
</p>

* 즉, 그래디언트 계산법에는 2가지가 있습니다.
    * 수치적 그래디언트: 근삿값을 계산하며, 계산이 느리지만, 쓰기 쉽습니다.
    * 해석적 그래디언트: 정확한 값을 계산하고, 빠르지만, error가 발생하기 쉽습니다.
* 실제로 그래디언트를 계산할때는, 항상 해석 그래디언트를 활용하면서 gradient check를 거칩니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/185568772-c104c5c7-4d95-4be7-9e18-0e771ec95386.png">
</p>
