---
layout: post
title: CS231n Lecture3 Review
category: CS231n
tag: CS231n
---

해당 게시물은 [Standford 2017 CS231n](http://cs231n.stanford.edu/2017/syllabus.html)을 바탕으로 작성되었습니다.





<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182162332-d243c0ec-1719-425a-8a54-f0008f3c169d.png">
</p>

<br>





# Linear Classifier: Choose a good $W$

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182266509-b22e5c44-7575-4cf4-89f4-63ca3f95a3a6.png">
</p>

* 본 강의에서는 어떻게 training data를 이용하여 가장 좋은 행렬 $W$를 구하는지에 대해 다룹니다.
* 위 예시는 세개의 training data에 대한 임의의 행렬W를 가지고 예측한 10개의 클래스 스코어입니다.
* 알고리즘을 만들고, 어떤 W가 가장 좋은지 결정하기 위해서는 지금 만든 W가 좋은지 나쁜지를 정량화 할 방법이 필요합니다.
    * Loss Function은 입력과 W와의 dot product를 통해 출력한 class score가 정량적으로 얼마나 나쁜지를 결정하는 함수입니다.
    * 즉, 최적의 $W$를 결정하기 위해 필요한 함수입니다.($W$의 optimization에 필요한 함수)
    * optimization은 손실 함수를 최소화하는 최적의 매개변수(parameter) $W$를 찾는 과정입니다.



# Suppose: 3 training examples, 3 classes

## With some W the scores $f(x, W)=Wx$ are:

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182267840-3e4727d1-ad22-470f-ac86-c88bd5bcda15.png" style="zoom:40%;">
</p>

간단한 예로, 고양이(cat), 자동차(car), 개구리(frog)의 3개의 class를 분류하는 classifier가 임의의 $W$ 값을 가진다고 할때, 위와 같이 세 개의 이미지에 대한 3개의 class score 가 임의로 나오게 됩니다.
* "고양이" 클래스는 잘 분류되지 못했고 "자동차"는 잘됐고 "개구리"는 최악입니다. 개구리 점수는 다른 것보다 더 낮습니다.
<br>

우리가 원하는 진정한 classifier는 고양이 이미지에서는 cat에 대한 score 가 가장 높게 나오고, 자동차 이미지에서는 car에 대한 score 가 가장 높게 나오고, 개구리 이미지에서는 frog에 대한 score 가 가장 높게 나오는 것입니다.

따라서 최적의 $W$를 찾아서 classifier 가 이미지들을 잘 분류하고 있는지 검사를 해야합니다. 즉, $W$ (weight) 가 좋은지 아닌지 정량화 할 수 있는 기준이 필요합니다.

<br>

손실 함수(Loss Function)는 현재 분류기(classifier)가 얼마나 좋은지를 알려줍니다. 다르게 표현하면 현재의 $W$ 가 얼마나 BADNESS 한지를 알려주는 것입니다.
* 주어진 데이터셋의 샘플 : $\{(x_i, y_i)\}^N_{i=1}$
* $x_i$ : 이미지
* $y_i$ : (정수)라벨(label),
    * 즉, 입력 이미지 $x_i$에 대한 정답 카테고리
    * CIFAR-10의 경우 y는 10개
* $f(x,W)=Wx$ : 입력 이미지 $x_i$와 가중치 행렬 $W$를 입력으로 받아서 새로운 테스트 이미지에 대해 $y_i$를 예측
<br>

데이터셋에 대한 Loss는 각 N개의 샘플에 대한 손실의 평균입니다.

$$L=\frac{1}{N}∑_iL_i(f(x_i,W),y_i)$$
    


## Multi-class SVM loss

Multi-class classification 문제에 사용할 수 있는 Loss function 중 하나인 SVM Loss를 살펴보겠습니다.

우선 스코어 벡터 $s$를 간결하게 나타냅니다.
* $s=f(x_i,W)$
* 예를 들어 $j$번째 클래스의 점수 $j$번째 요소입니다.
* $s_j=f(x_i,W)_j$

그다음 SVM 손실함수 $L_i$를 정의합니다.

$$L_i=∑_{j≠y_i}max(0, s_j − s_{y_i} + 1)$$

* $s_j$ : 정답이 아닌 클래스의 스코어
* $s_{y_i}$ : 정답 클래스의 스코어
* 1 : safety margin
* 여기서 $s_{y_i}$가 $s_j+1$보다 크면 loss는 0이 됩니다.



### Hinge loss(힌지 로스)

이 손실함수의 그래프 모양 때문에 SVM Loss 를 hinge loss라고 부르기도 합니다. 또한 정답 카테고리의 점수가 올라갈수록 Loss가 선형적으로 줄어드는 것을 알 수 있습니다. 이 로스는 0이 된 이후에도 Safety margin을 넘어설 때 까지 더 줄어듭니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182277993-79732453-1260-4979-b8a0-732b3fb83c93.png" style="zoom:40%;">
</p>

* Linear Classification인 $f(x_i, W)$ 에서 나온 스코어를 $s_j$ 라고 하고,
* 정답인 클래스의 스코어을 $s_{y_i}$ 라고 할때, 나머지 클래스와 이 값을 비교합니다.
* 정답인 클래스와 나머지를 비교했을때, 정답보다 다른 클래스의 점수가 더 높다면 이 차이 만큼이 Loss 라고 정의합니다.
* 또한 위에서 구한 Loss 에서 safety margin 이라는 값을 추가합니다. 이는 정답 클래스가 적어도 다른 클래스보다 safety margin 값 만큼은 커야 한다는 이야기이며, 여기서는 safety margin=1 입니다.
    * 같은말로, 예측 값과 정답 값에 대한 상대적인 차이를 주기 위해 설정합니다.
    * 즉, safty margin 은 정답클래스의 score 가 다른 score 보다 훨씬(safty margin만큼) 높아야 loss값이 줄어들게 하기 위해 적용하는 것입니다.
* 이 Loss 값이 0보다 작은 음수 값인 경우에는 포함하지 않습니다.
* 가로축은 $s_j - s_{y_i} + 1$ 값, 세로축은 $L_i$ 의 값인 Loss 값입니다.


Loss function을 의미하는 $L_i$는 $x_i$와 $W$로 이루어진 예측함수 $f$를 통해 만들어진 score 와 라벨 값 $y_i$를 입력으로 받아 해당 데이터를 얼마나 나쁘게 예측하는지를 정량화 시켜줍니다. 그리고 최종 Loss인 "L"은 $N$개의 training data에 대한 $L_i$들의 평균이 됩니다.

이 함수는 아주 일반적인 공식이며, Image classification 외에도 다양하게 확장할 수 있습니다.

좀 더 나아가서 어떤 알고리즘이던 가장 일반적으로 진행되는 일은, 어떤 X와 Y가 존재하고, 우리가 만들 파라미터 W가 얼마나 좋은지를 정량화하는 손실 함수를 만드는 것입니다. 즉 W의 공간을 탐색하면서 training data의 Loss를 최소화하는 어떤 W를 찾게 될 것입니다. 예제로 살펴보겠습니다.



## Calculate SVM Loss

$L_i$를 구하기 위해 올바른 카테고리의 스코어와 올바르지 않은 카테고리의 스코어를 비교하여 "True인 카테고리" 를 제외한 "나머지 카테고리 Y"의 합을 구합니다. 즉 맞지 않는 카테고리를 전부 합치는 것입니다. 만약 올바른 카테고리의 점수가 올바르지 않은 카테고리의 점수보다 더 높다면, 그리고 그 격차가 일정 마진(safety margin) 이상이라면, 이 경우 True인 스코어가 다른 false 카테고리보다 훨씬 더 크다는 것을 의미하며, 이렇게 되면 Loss는 0이 됩니다.

이미지 내 정답이 아닌 카테고리의 모든 값들을 합치면 그 값이 바로 한 이미지의 최종 Loss가 되고, 전체 training dataset에서 이 Loss들의 평균을 구합니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182281377-37352658-fad7-4e22-98a4-e98f91948576.png">
</p>

위와 같이 각 이미지에서 나온 class별 score을 이용해 SVM Loss를 계산했습니다.



### cat image SVM Loss

$$
L_{cat} = ∑_{j≠y_{cat}}max(0, s_j − s_{y_{cat}} + 1) \\
= max(0, 5.1-3.2+1) + max(0, -1.7-3.2+1) \\
= max(0, 2.9) + max(0, -3.9) \\
= 2.9 + 0 \\
= 2.9
$$

고양이 이미지에서는 정답 class (cat) 에 대한 score 가 3.2 인데 car class 에 대한 score 가 5.1로 더 높은 것을 보아 잘못 분류 한 것을 알 수 있고 계산한 Loss 값은 2.9 정도로 나온 것을 알 수 있습니다.



### car image SVM Loss

$$
L_{car} = ∑_{j≠y_{car}}max(0, s_j − s_{y_{car}} + 1) \\
= max(0, 1.3-4.9+1) + max(0, 2.0-4.9+1) \\
= max(0, -2.6) + max(0, -1.9) \\
= 0 + 0 \\
= 0
$$

자동차 이미지에서는 정답 class (car) 에 대한 score 가 4.9로 나머지 class 보다 높아 잘 분류했다고 할 수 있고 그에 따라 계산한 Loss 값은 0 이 나온 것을 알 수 있습니다.



### frog image SVM Loss

$$
L_{frog} = ∑_{j≠y_{frog}}max(0, s_j − s_{y_{frog}} + 1) \\
= max(0, 2.2-(-3.1)+1) + max(0, 2.5-(-3.1)+1) \\
= max(0, 6.3) + max(0, 6.6) \\
= 6.3 + 6.6 \\
= 12.9
$$

개구리 이미지에서는 정답 class (frog) 에 대한 score 가 -3.1 로 나머지 모든 class 의 score 보다도 더 낮게 나온 것을 보아 엄청 잘 못 분류했음을 알 수 있고 그에 따라 Loss 값도 12.9 로 엄청 크게 나온 것을 확인 할 수 있습니다.



### Loss over full dataset is average:

$$
L=(2.9 + 0 + 12.9) / 3 \\
= 5.27
$$

이를통해 모델이 잘못 예측한 정도(badness)에 따라 Loss 값이 높아짐을 알 수 있습니다.

Multiclass SVM Loss의 계산 과정은 다음과 같이 정리할 수 있다.
* 훈련 데이터 하나하나마다, 정답 class와 정답이 아닌 class간의 score를 비교하고, 이들을 모두 더한다.
    * 비교할 때, 정답 class의 score가 다른 class보다 1이상 높은 경우, 0이 되도록 1을 더해줌
    * 이때의 1을 safety margin이라고 함
* 앞에서 구한 값들의 평균을 구한다.





## Quiz

### Q1. hinge loss에서 safety margin 1을 더하는 것은 어떻게 결정하는지?

* 임의로 선택한 숫자같아 보이긴 하지만, 사실 손실함수의 "스코어가 정확이 몇인지"는 신경쓰지 않습니다. 우리가 궁금한건 여러 스코어 간의 상대적인 차이입니다. 즉 정답 스코어가 다른 스코어에 비해 얼마나 더 큰 스코어를 가지고 있는지 입니다.
* 행렬 $W$를 전체적으로 스케일링한다 가정한다면 결과 스코어도 이에 따라 스케일이 바뀔 것입니다. 그렇다면 1 이라는게 별 상관은 없습니다.



### Q2. Car 스코어가 조금 변하면 Loss에는 무슨 일이 일어나는가?

* SVM loss는 오직 정답 스코어와 그 외의 스코어와의 차이만 고려합니다.
* 따라서 이 경우에는 Car 스코어가 이미 다른 스코어들보다 엄청 높기 때문에 Car의 스코어를 조금 바꾼다고 해도, 서로 간의 간격(Margin)은 여전히 유지될 것이고, 결국 Loss는 변하지 않습니다. 계속 0일 것입니다.



### Q3. SVM Loss가 가질 수 있는 최대/최소값은?

* 모든 클래스에 걸쳐 정답 클래스의 스코어가 제일 크면 모든 training data에서 loss가 0이 됩니다. 그러므로 최소값은 0입니다.
* 만약 정답 클래스 스코어가 엄청 낮은 음수 값을 가지고 있다고 할 때, Loss는 무한대 일 것입니다. 그러므로 최대값은 $\infty$ 입니다.



### Q4. 파라미터를 초기화하고 처음 학습을 시킬때 보통 $W$를 임의의 작은 값으로 초기화 시키는데 그렇다면 처음 학습 완료 후에는 모든 결과에 대한 score 가 임의의 일정한 작은값 (0에 근사) 을 갖게 됩니다. 이럴 경우의 multiclass SVM Loss 값이 어떻게 되나요?

* Loss 값은 클래스 개수 - 1 (safty margin) 이 됩니다.
* 또한 이 방법은 디버깅할 때 유용히 쓰입니다. 모든 score 값이 근사해지면서 정답을 제외한 class의 score 에서 $max(0, s_j − s_{y_i} + 1)$ 의 값이 1 (safty margin)이 되게 됩니다. 그러므로 정답을 제외한 class score에 대한 Loss를 모두 합친 최종 Loss 값은 "클래수 개수 - 1 (safty margin)" 이 됩니다.



### Q5. SVM Loss는 정답인 클래스는 빼고 다 더했는데, loss 계산에서, 모든 class(정답 class와 정답 class 자신을 비교하는 경우 포함)에서 값을 구한 후, sum을 취하면 어떻게 되나요?

* Loss에 1이 더 증가합니다.
* 정답 클래스만 빼고 계산하는 이유는, 일반적으로 Loss가 0이 되야지만 우리가 "아무것도 잃는 것이 없다"고 쉽게 해석할 수 있으며, Loss에 모든 클래스를 다 더한다고 해서 다른 분류기가 학습되는 것은 아닙니다. 하지만 관례상 정답 클래스는 빼고 계산을 하며, 그렇게 되면 최소 Loss는 0이 됩니다.



### Q6. 최종 loss 를 계산할때 정답을 제외한 각 class 에서 계산한 loss 값들의 합(sum) 대신에 평균(mean) 을 이용하면 어떻게 되나요?

* 전체 loss에 대한 scaling의 의미만 가지므로, 큰 변화는 없으며, 상관 없습니다.
* 왜냐하면 스코어 값이 몇인지는 신경쓰지 않기 때문입니다.



### Q7. multiclass SVM loss 를 계산하는 수식에서 $max(0, s_j − s_{y_i} + 1)$ 대신 $max(0, s_j − s_{y_i} + 1)^2$ 를 사용하면 Loss가 어떻게 변하나요?

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182318727-3c288677-9107-4ac8-bc69-52709000e145.png" style="zoom:40%;">
</p>

* 결과는 달라집니다.
* 좋은것과 나쁜것의 trade off를 비선형 방식으로 바꾸게 되는 것으로, 다른 loss function이 됩니다. 또한 이런 Loss를 squared hinge loss라 칭합니다.
    * squared loss는 잘못된 것을 아주 잘못된 것으로, hinge loss는 그것보다는 조금 덜하게 계산합니다.
    * 잘못된 것을 얼마나 고려할 것인가? 라는 문제는 에러에 대해 얼마나 신경쓰고 있고, 그것을 어떻게 정량화 할 것인지에 달려있으며, loss function을 고려할 때 생각해야 할 내용입니다.
* 손실 함수는 알고리즘에게 "어떤 에러를 내가 신경쓰고 있는지" 그리고 "어떤 에러가 트레이드오프 되는 것인지"를 알려주는 것입니다. 때문에 실제로 문제에 따라서 손실함수를 잘 설계하는 것은 엄청 중요합니다.

<br>





# Regularization



## Train Loss = 0: Overfitting

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182319486-3ae336a4-4f0a-44e6-bc18-60d7993d5db8.png" style="zoom:30%;">
</p>

만약 Multiclass SVM Loss가 0이 되었다고 할때, 과연 Loss가 0이 되는 이때의 $W$는 unique할지 생각해봐야합니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182321278-ece01a95-5eb0-4617-9445-c0476d5d49c7.png">
</p>

위 슬라이드의 오른쪽과 같이 직접 계산을 해보면, W를 2배로 해도 Loss는 같게 계산되기 때문에 W는 유일하지 않습니다. W의 스케일이 변하더라도 그대로 Loss 값은 0 으로 변하지 않을 것입니다. 즉, W 를 두 배한 2W 도 Loss값이 0 이 나올 것입니다.

조금 이상합니다.

Loss Function 이란 것은, 우리의 classifier가 현재 얼마나 badness한지 알려주는 기준이고, Loss가 최소가 되면 우리의 classifier가 좋은 성능을 보인다고 했습니다. 그러므로 Loss가 최소가 되는 W값을 찾는게 좋은 classifier를 만드는 것이라 할 수 있습니다. 이러한 관점에서는 Loss 가 0이 되는 수 많은 W 들 중에 아무거나 선택해서 사용하면 좋은 성능의 classifier 가 될 것이라고 생각이 듭니다.

하지만 Loss Function이 정말 classifier에게 우리는 어떤 W를 찾고 있고, 어떤 W에 신경쓰고 있는지를 말해주는 것이라면, Loss 값이 0이 되는 수 많은 W의 값들 중에서 어떤 W 값을 선택하는것은 좀 이상합니다. 즉 본질이 불일치하며 모순적입니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182354809-6c083a3d-3e86-4445-8f73-999c175ccd89.png" style="zoom:40%;">
</p>

여기서 간과한 점이 있는데, 위 수식처럼 Loss를 0으로 만드는 W를 구하는 것에 초점을 맞추는 것은 학습과정에서 training data에 대한 loss에 대해서만 생각한다는 것 입니다. 즉 classifier에게 training data에 꼭 맞는 W를 찾으라고 말하는것과 같습니다.

하지만 실제 만들려고하는 classifier는 training data를 얼마나 fit한지(잘 분류하는냐)에 대해서는 신경쓰지않습니다.

기계학습의 핵심은, training data를 이용해서 어떤 classifier를 찾는 것인데, 분류기는 test data에 적용할 것이기 때문에 training data의 성능이 아니라, test data의 성능에 관심을 두어야 합니다. 최종적으로는 실제 test data 를 얼마나 잘 분류하느냐가 중요하기 때문입니다. 그러므로 classifier에게 training data의 Loss에만 신경쓰라고 한다면 분류기가 이해할 수 없는 행동을 할 수도 있습니다.



## Regularization intuition: Prefer Simpler Models

선형 분류기가 아닌, 기계학습에서 다루는 좀 더 일반적인 개념에 대한 구체적인 예를 들겠습니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182359791-9141be5a-1f21-4993-92e5-22e825657801.png">
</p>

파란 점은 training data를 의미하며, 우리가 유일하게 하는 일은 classifier에게 파란 training data에 대해 fitting하라 시키는 것입니다. 그럼 classifier는 모든 training data에 대해 완벽히 fitting 하기위해 (즉, training data에 대한 loss가 0이 되기위해) 우리의 모델(classifier)은 구불구불한 파란색 곡선 $f1$ 을 만들 것입니다.

하지만 새로운 흰색 test data에 대한 성능에 대해 전혀 고려하지 않았기 때문에 좋지않습니다. 항상 테스트 데이터의 성능을 고려해야 합니다. 만약 새로운 흰색 test data가 들어오게 되면 앞에서 만든 파란색 곡선의 모델인 $f1$ 은 새로운 흰색 data에 대해 완전히 틀리게 됩니다.

사실 우리가 의도했던건 초록색 선 $f2$ 입니다. 완벽하게 training data에 fit한 복잡하고 구불 구불한 곡선을 원한 것이 아닙니다. 만약 새로운 test data가 들어왔을 때 일반화 성능을 고려하지 않고 training data에만 맞추면, Overfitting이 됩니다. 이 문제는 Overfitting을 의미하며 기계학습에서 가장 중요한 문제입니다. 이러한 문제를 해결하는 것이 바로 Regularization입니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182360468-5255ecf0-5cee-4ae2-b409-c37bb4f31e44.png">
</p>

training data에 대한 loss값을 구하는 기존의 손실함수에 하나의 항인 Regularization term을 더해 모델이 더 단순한 W값을 선택하도록 합니다.
* Overftting을 방지하는 장치입니다.
* 위 그림의 complex한 파란 $f1$에서 simple한 초록 $f2$가 되도록 합니다.
* 기계학습에서 "Regularization penalty" 를 만들어 R로 표기를 합니다.
* 일반적인 손실 함수의 형태는 두가지 항을 가지게 됩니다. 즉 Data loss와 Regularization loss입니다.


그리고 $R(W)$에 하이퍼파라미터 $λ$를 붙여 training data에 fit하게 만드는 것에 더 중점을 둘지, 모델을 단순화하는데 더 중점을 둘지에 대한 trade-off 관계를 설정할 수 있습니다.
* $λ$ 값 높으면 모델이 단순해짐 -> underfitting 위험
* $λ$ 값 낮으면 모델이 복잡해짐 -> overfitting 위험



### Why regularize?

* 가중치에 대한 선호도를 표현하기 위해서.
* 모델을 simple하게 만들어 test data에서 작동하게 만들기 위해서.
* 곡면성(curvature)을 추가하여 Optimization을 향상시키기 위해서.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182363432-516db31b-1b09-4e20-ba12-f4651d2b08e6.png">
</p>

Regularization 에는 여러 종류들이 있습니다.
* 머신러닝/딥러닝 모두에서 볼 수 있는 것들
    * L2 Regularization(Weight decay) (가장 일반적)
    * L1 Regularization, Elastic net(L1과 L2를 같이 사용), Max norm regularization 등
* 주로 딥러닝에서 볼 수 있는 것들
    * Dropout, Batch normalization, stochastic depth 등



## Regularization: Expressing Preferences

다음 슬라이드는 입력 벡터 $x$와 가중치 벡터 $w$가 있을 때, Linear classification의 관점에서 내적이 같기때문에 w1와 w2는 같습니다. 출력은 동일하지만 $w$의 형태가 다른 경우를 보여줍니다.
* $w_1^T x = w_2^T x = 1$ 로 모두 동일

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182365578-e550c540-05dd-44ab-8e62-b264f78f515a.png" style="zoom:20%;">
</p>


이때, L1과 L2 regularization이 weight vector가 어떻게 구성되는 것을 더 선호하는지는 L1, L2 norm을 계산해봄으로써 알 수 있습니다.(여기서, 선호한다는 것은 penalty를 덜 준다는 것을 의미)
* L1 norm
    * $\left\Vert w_1 \right\Vert _1 = \left \vert 1 \right \vert + \left \vert 0 \right \vert + \left \vert 0 \right \vert + \left \vert 0 \right \vert = 1$
    * $\left\Vert w_2 \right\Vert _1 = \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert = 1$
    * L1 norm이 작게 나오려면 vector의 element들이 0에 가까워야 하므로 sparse해지는 것을 더 선호합니다. (위 예에서는 어쩌다보니 값이 동일하게 나왔음)
* L2 norm
    * $\left\Vert w_1 \right\Vert _2 = \sqrt{1^2 + 0^2 + 0^2 + 0^2} = 1$
    * $\left\Vert w_2 \right\Vert _2 = \sqrt{0.25^2 + 0.25^2 + 0.25^2 + 0.25^2} = 0.25$
    * L2 norm이 작게 나오려면 vector의 element들이 고르게 분포해야 하므로 값이 더 넓게 퍼지는 것을 더 선호합니다.
    

따라서, L1과 L2 Regularization이 모델에 미치는 영향에 대한 직관은 다음과 같이 서로 반대라는 것을 알 수 있습니다.
* L1 regularization
    * W가 sparse해지도록 합니다.
    * 작은 가중치들이 0으로 수렴하게 하고, 몇개의 중요한 가중치만 남도록 합니다.
    * 가중치 W에 대해 0의 갯수에 따라 모델의 복잡도를 다룹니다.
    * 즉 L1이 "복잡하다"고 느끼고 측정하는 것은 0이 아닌 요소들의 갯수입니다.
    * 또한 의미 있는 값을 원하면 L1 regularization 이 좋습니다.
* L2 regularization
    * W에서 특정 값만 모델에 큰 영향을 미치도록 하지 않습니다.즉 가중치를 0에 가깝게 유도합니다.
    * W의 값이 고르고 넓게 퍼지도록(spread) 합니다. 즉 모든 데이터를 고려합니다.
    * L2 Regression은 분류기의 복잡도를 상대적으로 w1와 w2중 어떤 것이 더 coarse한지를 측정합니다. (값이 매끄러워야함)
    * Linear classification에서 W가 의미하는 것은, "얼마나 x가 Output Class와 닮았는지" 이므로, L2 Regularization이 말하고자 하는것은 x의 모든 요소가 영향을 줬으면 하는 것입니다. 
    * 그러므로 변동이 심한 어떤 입력 x의 특정 요소에만 의존하기 보다, 모든 x의 요소가 골고루 영향을 미치길 원한다면, L2 Regularization을 통해 더 강건합니다.
    * 즉 L2의 경우에는 W의 요소가 전체적으로 퍼져있을 때 "덜 복잡하다" 라고 생각하게 됩니다.

즉, 풀고자 하는 문제에 따라 모델의 복잡도를 어떻게 바라볼 것인가(모델의 복잡도에 어떻게 penalty를 주어서 제한할 것인가)를 결정하고, 이에 적절한 regularization을 고르는 것이 중요합니다.
* L1
    * w에 0이 아닌 요소가 많을때: 복잡
    * w에 0이 많으면: 덜 복잡
* L2
    * w의 요소가 퍼져있을 때: 덜 복잡
    * w가 어느 쪽에 치중되어 있으면: 복잡


정리하자면 결국 모델을 덜 복잡하게 만들기 위한 것이 Regularization의 궁극적인 목표입니다. 또다른 말로 Hypothesis class중에 더 간단한 것을 선택하기 위해서 우리는 model에 Penalty를 주는 것입니다. 

<br>





#  Softmax Classifier(Multinomial Logistic Regression)


<p align="center">
<img alt="image" src="">
</p>
