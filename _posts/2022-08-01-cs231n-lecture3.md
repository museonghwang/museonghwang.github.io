---
layout: post
title: CS231n Lecture3 Review
category: CS231n
tag: CS231n
---

해당 게시물은 [Standford 2017 CS231n](http://cs231n.stanford.edu/2017/syllabus.html) 강의와 2022년 슬라이드를 바탕으로 작성되었습니다.




<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182162332-d243c0ec-1719-425a-8a54-f0008f3c169d.png">
</p>

<br>





# Linear Classifier: Choose a good $W$

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182266509-b22e5c44-7575-4cf4-89f4-63ca3f95a3a6.png">
</p>

* 본 강의에서는 어떻게 training data를 이용하여 가장 좋은 행렬 $W$를 구하는지에 대해 다룹니다.
* 위 예시는 세개의 training data에 대한 임의의 행렬W를 가지고 예측한 10개의 클래스 스코어입니다.
* 알고리즘을 만들고, 어떤 W가 가장 좋은지 결정하기 위해서는 지금 만든 W가 좋은지 나쁜지를 정량화 할 방법이 필요합니다.
    * Loss Function은 입력과 W와의 dot product를 통해 출력한 class score가 정량적으로 얼마나 나쁜지를 결정하는 함수입니다.
    * 즉, 최적의 $W$를 결정하기 위해 필요한 함수입니다.($W$의 optimization에 필요한 함수)
    * optimization은 손실 함수를 최소화하는 최적의 매개변수(parameter) $W$를 찾는 과정입니다.

<br>





# Suppose: 3 training examples, 3 classes

## With some W the scores $f(x, W)=Wx$ are:

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182267840-3e4727d1-ad22-470f-ac86-c88bd5bcda15.png" style="zoom:40%;">
</p>

간단한 예로, 고양이(cat), 자동차(car), 개구리(frog)의 3개의 class를 분류하는 classifier가 임의의 $W$ 값을 가진다고 할때, 위와 같이 세 개의 이미지에 대한 3개의 class score 가 임의로 나오게 됩니다.
* "고양이" 클래스는 잘 분류되지 못했고 "자동차"는 잘됐고 "개구리"는 최악입니다. 개구리 점수는 다른 것보다 더 낮습니다.
* 우리가 원하는 진정한 classifier는 고양이 이미지에서는 cat에 대한 score 가 가장 높게 나오고, 자동차 이미지에서는 car에 대한 score 가 가장 높게 나오고, 개구리 이미지에서는 frog에 대한 score 가 가장 높게 나오는 것입니다.

<br>

**<span style="background-color: #fff5b1">따라서 최적의 $W$ 를 찾아서 classifier가 이미지들을 잘 분류하고 있는지 검사를 해야합니다.</span>** **<span style="color:red">즉, $W$ (weight) 가 좋은지 아닌지 정량화 할 수 있는 기준이 필요합니다.</span>**

<br>

**<span style="color:red">손실 함수(Loss Function)</span>** 는 **<span style="background-color: #fff5b1">현재 분류기(classifier)가 얼마나 좋은지</span>** 를 알려줍니다. 다르게 표현하면 **<span style="background-color: #fff5b1">현재의 $W$ 가 얼마나 BADNESS 한지</span>** 를 알려주는 것입니다.
* 주어진 데이터셋의 샘플 : $\{(x_i, y_i)\}^N_{i=1}$
* $x_i$ : 이미지
* $y_i$ : (정수)라벨(label),
    * 즉, 입력 이미지 $x_i$에 대한 정답 카테고리
    * CIFAR-10의 경우 y는 10개
* $f(x,W)=Wx$ : 입력 이미지 $x_i$와 가중치 행렬 $W$를 입력으로 받아서 새로운 테스트 이미지에 대해 $y_i$를 예측

<br>

**<span style="color:red">데이터셋에 대한 Loss</span>** 는 **<span style="background-color: #fff5b1">각 N개의 샘플에 대한 손실의 평균</span>** 입니다.

$$L=\frac{1}{N}∑_iL_i(f(x_i,W),y_i)$$
    


## Multi-class SVM loss

Multi-class classification 문제에 사용할 수 있는 Loss function 중 하나인 **<span style="color:red">SVM Loss</span>**를 살펴보겠습니다.

우선 스코어 벡터 $s$를 간결하게 나타냅니다.
* $s=f(x_i,W)$
* 예를 들어 $j$번째 클래스의 점수 $j$번째 요소입니다.
* $s_j=f(x_i,W)_j$

그다음 SVM 손실함수 $L_i$를 정의합니다.

$$L_i=∑_{j≠y_i}max(0, s_j − s_{y_i} + 1)$$

* $s_j$ : 정답이 아닌 클래스의 스코어
* $s_{y_i}$ : 정답 클래스의 스코어
* 1 : safety margin
* 여기서 $s_{y_i}$가 $s_j+1$보다 크면 loss는 0이 됩니다.



### Hinge loss(힌지 로스)

이 손실함수의 그래프 모양 때문에 SVM Loss를 **<span style="color:red">hinge loss</span>**라고 부르기도 합니다. 또한 정답 카테고리의 점수가 올라갈수록 Loss가 선형적으로 줄어드는 것을 알 수 있습니다. 해당 loss는 0이 된 이후에도 Safety margin을 넘어설 때 까지 더 줄어듭니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182277993-79732453-1260-4979-b8a0-732b3fb83c93.png" style="zoom:30%;">
</p>

* Linear Classification인 $f(x_i, W)$ 에서 나온 score를 $s_j$ 라고 하고,
* 정답인 클래스의 score를 $s_{y_i}$ 라고 할때, 나머지 클래스와 이 값을 비교합니다.
* 정답인 클래스와 나머지를 비교했을때, 정답보다 다른 클래스의 점수가 더 높다면 이 차이 만큼이 Loss 라고 정의합니다.
* 또한 위에서 구한 Loss에서 safety margin이라는 값을 추가합니다. 이는 정답 클래스가 적어도 다른 클래스보다 safety margin 값 만큼은 커야 한다는 이야기이며, 여기서는 safety margin=1 입니다.
    * 같은말로, **<span style="background-color: #fff5b1">예측 값과 정답 값에 대한 상대적인 차이를 주기 위해 설정</span>** 합니다.
    * 즉, **<span style="background-color: #fff5b1">safty margin은 정답클래스의 score가 다른 score에 비해 safty margin만큼 높아야, loss값이 줄어들게 하기 위해 적용하는 것</span>** 입니다.
* 이 Loss 값이 0보다 작은 음수 값인 경우에는 포함하지 않습니다.
* 가로축은 $s_j - s_{y_i} + 1$ 값, 세로축은 $L_i$ 의 값인 Loss 값입니다.

<br>

Loss function을 의미하는 **<span style="color:red">$L_i$</span>**는 **<span style="background-color: #fff5b1">$x_i$와 $W$로 이루어진 예측함수 $f$를 통해 만들어진 score 와 라벨 값 $y_i$를 입력으로 받아 해당 데이터를 얼마나 나쁘게 예측하는지를 정량화 시켜줍니다.</span>** 그리고 최종 Loss인 **<span style="color:red">"L"</span>**은 **<span style="background-color: #fff5b1">$N$개의 training data에 대한 $L_i$들의 평균</span>** 이 됩니다.

이 함수는 아주 일반적인 공식이며, Image classification 외에도 다양하게 확장할 수 있습니다.

좀 더 나아가서 어떤 알고리즘이던 가장 일반적으로 진행되는 일은, 어떤 X와 Y가 존재하고, 우리가 만들 파라미터 W가 얼마나 좋은지를 정량화하는 손실 함수를 만드는 것입니다. 즉 $W$의 공간을 탐색하면서 training data의 Loss를 최소화하는 어떤 $W$를 찾게 될 것입니다. 예제로 살펴보겠습니다.



## Calculate SVM Loss

$L_i$를 구하기 위해 올바른 카테고리의 스코어와 올바르지 않은 카테고리의 스코어를 비교하여 "True인 카테고리" 를 제외한 "나머지 카테고리 Y"의 합을 구합니다. **<span style="background-color: #fff5b1">즉 맞지 않는 카테고리를 전부 합치는 것입니다.</span>** 만약 올바른 카테고리의 점수가 올바르지 않은 카테고리의 점수보다 더 높다면, 그리고 그 격차가 일정 마진(safety margin) 이상이라면, 이 경우 True인 스코어가 다른 false 카테고리보다 훨씬 더 크다는 것을 의미하며, 이렇게 되면 Loss는 0이 됩니다.

이미지 내 정답이 아닌 카테고리의 모든 값들을 합치면 그 값이 바로 한 이미지의 최종 Loss가 되고, 전체 training dataset에서 이 Loss들의 평균을 구합니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182281377-37352658-fad7-4e22-98a4-e98f91948576.png">
</p>

위와 같이 각 이미지에서 나온 class별 score을 이용해 SVM Loss를 계산했습니다.



### cat image SVM Loss

$$
L_{cat} = ∑_{j≠y_{cat}}max(0, s_j − s_{y_{cat}} + 1) \\
= max(0, 5.1-3.2+1) + max(0, -1.7-3.2+1) \\
= max(0, 2.9) + max(0, -3.9) \\
= 2.9 + 0 \\
= 2.9
$$

고양이 이미지에서는 정답 class(cat)에 대한 scor 가 3.2 인데 car class에 대한 score가 5.1로 더 높은 것을 보아 잘못 분류 한 것을 알 수 있고 계산한 Loss 값은 2.9 정도로 나온 것을 알 수 있습니다.



### car image SVM Loss

$$
L_{car} = ∑_{j≠y_{car}}max(0, s_j − s_{y_{car}} + 1) \\
= max(0, 1.3-4.9+1) + max(0, 2.0-4.9+1) \\
= max(0, -2.6) + max(0, -1.9) \\
= 0 + 0 \\
= 0
$$

자동차 이미지에서는 정답 class(car)에 대한 score가 4.9로 나머지 class보다 높아 잘 분류했다고 할 수 있고 그에 따라 계산한 Loss 값은 0이 나온 것을 알 수 있습니다.



### frog image SVM Loss

$$
L_{frog} = ∑_{j≠y_{frog}}max(0, s_j − s_{y_{frog}} + 1) \\
= max(0, 2.2-(-3.1)+1) + max(0, 2.5-(-3.1)+1) \\
= max(0, 6.3) + max(0, 6.6) \\
= 6.3 + 6.6 \\
= 12.9
$$

개구리 이미지에서는 정답 class(frog)에 대한 score 가 -3.1로 나머지 모든 class의 score 보다도 더 낮게 나온 것을 보아 엄청 잘 못 분류했음을 알 수 있고 그에 따라 Loss 값도 12.9로 엄청 크게 나온 것을 확인 할 수 있습니다.



### Loss over full dataset is average:

$$
L=(2.9 + 0 + 12.9) / 3 \\
= 5.27
$$

이를통해 모델이 잘못 예측한 정도(badness)에 따라 Loss값이 높아짐을 알 수 있습니다.

Multiclass SVM Loss의 계산 과정은 다음과 같이 정리할 수 있다.
* 훈련 데이터 하나하나마다, 정답 class와 정답이 아닌 class간의 score를 비교하고, 이들을 모두 더한다.
    * 비교할 때, 정답 class의 score가 다른 class보다 1이상 높은 경우, 0이 되도록 1을 더해줌
    * 이때의 1을 safety margin이라고 함
* 앞에서 구한 값들의 평균을 구한다.

<br>





## Quiz

### Q1. hinge loss에서 safety margin 1을 더하는 것은 어떻게 결정하는지?

* 임의로 선택한 숫자같아 보이긴 하지만, 사실 손실함수의 "스코어가 정확이 몇인지"는 신경쓰지 않습니다. 우리가 궁금한건 여러 스코어 간의 상대적인 차이입니다. 즉 정답 스코어가 다른 스코어에 비해 얼마나 더 큰 스코어를 가지고 있는지 입니다.
* 행렬 $W$를 전체적으로 스케일링한다 가정한다면 결과 스코어도 이에 따라 스케일이 바뀔 것입니다. 그렇다면 1이라는게 별 상관은 없습니다.



### Q2. Car 스코어가 조금 변하면 Loss에는 무슨 일이 일어나는가?

* SVM loss는 오직 정답 스코어와 그 외의 스코어와의 차이만 고려합니다.
* 따라서 이 경우에는 Car 스코어가 이미 다른 스코어들보다 엄청 높기 때문에 Car의 스코어를 조금 바꾼다고 해도, 서로 간의 간격(Margin)은 여전히 유지될 것이고, 결국 Loss는 변하지 않습니다. 계속 0일 것입니다.



### Q3. SVM Loss가 가질 수 있는 최대/최소값은?

* 모든 클래스에 걸쳐 정답 클래스의 스코어가 제일 크면 모든 training data에서 loss가 0이 됩니다. 그러므로 최소값은 0입니다.
* 만약 정답 클래스 스코어가 엄청 낮은 음수 값을 가지고 있다고 할 때, Loss는 무한대 일 것입니다. 그러므로 최대값은 $\infty$ 입니다.



### Q4. 파라미터를 초기화하고 처음 학습을 시킬때 보통 $W$를 임의의 작은 값으로 초기화 시키는데 그렇다면 처음 학습 완료 후에는 모든 결과에 대한 score 가 임의의 일정한 작은값 (0에 근사) 을 갖게 됩니다. 이럴 경우의 multiclass SVM Loss 값이 어떻게 되나요?

* Loss 값은 (class개수 - 1) * safty margin 이 됩니다.
* 또한 이 방법은 디버깅할 때 유용히 쓰입니다. 모든 score 값이 근사해지면서 정답을 제외한 class의 score 에서 $max(0, s_j − s_{y_i} + 1)$ 의 값이 1 (safty margin)이 되게 됩니다. 그러므로 정답을 제외한 class score에 대한 Loss를 모두 합친 최종 Loss 값은 "(class개수 - 1) * safty margin" 이 됩니다.



### Q5. SVM Loss는 정답인 클래스는 빼고 다 더했는데, loss 계산에서, 모든 class(정답 class와 정답 class 자신을 비교하는 경우 포함)에서 값을 구한 후, sum을 취하면 어떻게 되나요?

* Loss에 1이 더 증가합니다.
* 정답 클래스만 빼고 계산하는 이유는, 일반적으로 Loss가 0이 되야지만 우리가 "아무것도 잃는 것이 없다"고 쉽게 해석할 수 있으며, Loss에 모든 클래스를 다 더한다고 해서 다른 분류기가 학습되는 것은 아닙니다. 하지만 관례상 정답 클래스는 빼고 계산을 하며, 그렇게 되면 최소 Loss는 0이 됩니다.



### Q6. 최종 loss 를 계산할때 정답을 제외한 각 class 에서 계산한 loss 값들의 합(sum) 대신에 평균(mean) 을 이용하면 어떻게 되나요?

* 전체 loss에 대한 scaling의 의미만 가지므로, 큰 변화는 없으며, 상관 없습니다.
* 왜냐하면 스코어 값이 몇인지는 신경쓰지 않기 때문입니다.



### Q7. multiclass SVM loss 를 계산하는 수식에서 $max(0, s_j − s_{y_i} + 1)$ 대신 $max(0, s_j − s_{y_i} + 1)^2$ 를 사용하면 Loss가 어떻게 변하나요?

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182318727-3c288677-9107-4ac8-bc69-52709000e145.png" style="zoom:30%;">
</p>

* 결과는 달라집니다.
* 좋은것과 나쁜것의 trade off를 비선형 방식으로 바꾸게 되는 것으로, 다른 loss function이 됩니다. 또한 이런 Loss를 squared hinge loss라 칭합니다.
    * squared loss는 잘못된 것을 아주 잘못된 것으로, hinge loss는 그것보다는 조금 덜하게 계산합니다.
    * 잘못된 것을 얼마나 고려할 것인가? 라는 문제는 에러에 대해 얼마나 신경쓰고 있고, 그것을 어떻게 정량화 할 것인지에 달려있으며, loss function을 고려할 때 생각해야 할 내용입니다.
* Loss function은 알고리즘에게 "어떤 error를 내가 신경쓰고 있는지" 그리고 "어떤 error가 trade-off 되는 것인지"를 알려주는 것입니다. 때문에 실제로 문제에 따라서 손실함수를 잘 설계하는 것은 엄청 중요합니다.

<br>





# Regularization



## Train Loss = 0: Overfitting

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182319486-3ae336a4-4f0a-44e6-bc18-60d7993d5db8.png" style="zoom:30%;">
</p>

만약 Multiclass SVM Loss가 0이 되었다고 할때, 과연 Loss가 0이 되는 이때의 $W$는 unique할지 생각해봐야합니다.

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182321278-ece01a95-5eb0-4617-9445-c0476d5d49c7.png">
</p>

위 슬라이드의 오른쪽과 같이 직접 계산을 해보면, $W$를 2배로 해도 Loss는 같게 계산되기 때문에 $W$는 유일하지 않습니다. $W$의 스케일이 변하더라도 그대로 Loss 값은 0으로 변하지 않을 것입니다. 즉, $W$ 를 두 배한 $2W$ 도 Loss값이 0이 나올 것입니다.

조금 이상합니다.

Loss Function 이란 것은, 우리의 classifier가 현재 얼마나 badness한지 알려주는 기준이고, Loss가 최소가 되면 우리의 classifier가 좋은 성능을 보인다고 했습니다. 그러므로 **<span style="background-color: #fff5b1">Loss가 최소가 되는 $W$ 값을 찾는게 좋은 classifier를 만드는 것</span>** 이라 할 수 있습니다. 이러한 관점에서는 Loss 가 0이 되는 수 많은 $W$ 들 중에 아무거나 선택해서 사용하면 좋은 성능의 classifier가 될 것이라고 생각이 듭니다.

**<span style="color:red">하지만</span>** Loss Function이 정말 classifier에게 우리는 어떤 $W$를 찾고 있고, 어떤 $W$ 에 신경쓰고 있는지를 말해주는 것이라면, **<span style="color:red"> Loss값이 0이 되는 수 많은 $W$ 의 값들 중에서 어떤 $W$ 값을 선택하는것은 좀 이상합니다.</span>** **<span style="color:red">즉 본질이 불일치하며 모순적입니다.</span>**

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182354809-6c083a3d-3e86-4445-8f73-999c175ccd89.png" style="zoom:40%;">
</p>

여기서 간과한 점이 있는데, 위 수식처럼 **<span style="background-color: #fff5b1">Loss를 0으로 만드는 $W$ 를 구하는 것에 초점을 맞추는 것은 학습과정에서 training data에 대한 loss에 대해서만 생각한다는 것</span>** 입니다.**<span style="color:red">즉 classifier에게 training data에 꼭 맞는 $W$ 를 찾으라고 말하는것</span>** 과 같습니다.

하지만 실제 만들려고하는 classifier는 training data를 얼마나 fit한지(잘 분류하는냐)에 대해서는 신경쓰지않습니다.

**<span style="color:red">기계학습의 핵심은, training data를 이용해서 어떤 classifier를 찾는 것인데</span>**, **<span style="color:red">분류기는</span>** test data에 적용할 것이기 때문에 training data의 성능이 아니라, **<span style="color:red">test data의 성능에 관심을 두어야 합니다.</span>** 최종적으로는 실제 test data 를 얼마나 잘 분류하느냐가 중요하기 때문입니다. 그러므로 classifier에게 training data의 Loss에만 신경쓰라고 한다면 분류기가 이해할 수 없는 행동을 할 수도 있습니다.



## Regularization intuition: Prefer Simpler Models

선형 분류기가 아닌, 기계학습에서 다루는 좀 더 일반적인 개념에 대한 구체적인 예를 들겠습니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182359791-9141be5a-1f21-4993-92e5-22e825657801.png">
</p>

**<span style="color:blue">파란 점</span>**은 **<span style="color:blue">training data</span>** 를 의미하며, 우리가 유일하게 하는 일은 classifier에게 파란 training data에 대해 fitting하라 시키는 것입니다. 그럼 classifier는 모든 training data에 대해 완벽히 fitting 하기위해(즉, training data에 대한 loss가 0이 되기위해) 우리의 모델(classifier)은 **<span style="color:blue">구불구불한 파란색 곡선 $f1$</span>** 을 만들 것입니다.

**<span style="color:red">하지만 새로운 흰색 test data에 대한 성능에 대해 전혀 고려하지 않았기 때문에 좋지않습니다. 항상 테스트 데이터의 성능을 고려해야 합니다.</span>** 만약 새로운 흰색 test data가 들어오게 되면 앞에서 만든 파란색 곡선의 모델인 $f1$ 은 새로운 흰색 data에 대해 완전히 틀리게 됩니다.

**<span style="color:green">사실 우리가 의도했던건 초록색 선 $f2$</span>** 입니다. 완벽하게 training data에 fit한 복잡하고 구불 구불한 곡선을 원한 것이 아닙니다. **<span style="background-color: #fff5b1">만약 새로운 test data가 들어왔을 때 일반화 성능을 고려하지 않고 training data에만 맞추면,</span>** **<span style="color:red">Overfitting이 됩니다.</span>** 이 문제는 Overfitting을 의미하며 기계학습에서 가장 중요한 문제입니다. 이러한 문제를 해결하는 것이 바로 **<span style="color:red">Regularization</span>**입니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182360468-5255ecf0-5cee-4ae2-b409-c37bb4f31e44.png">
</p>

training data에 대한 loss값을 구하는 기존의 손실함수에 하나의 항인 **<span style="color:red">Regularization term</span>** 을 더해 모델이 더 단순한 $W$ 값을 선택하도록 합니다.
* **<span style="background-color: #fff5b1">Overftting을 방지하는 장치입니다.</span>**
* 위 그림의 complex한 파란 $f1$에서 simple한 초록 $f2$가 되도록 합니다.
* 기계학습에서 "Regularization penalty" 를 만들어 R로 표기를 합니다.
* 일반적인 손실 함수의 형태는 두가지 항을 가지게 됩니다. 즉 **<span style="color:red">Data loss</span>** 와 **<span style="color:red">Regularization loss</span>** 입니다.


그리고 $R(W)$에 하이퍼파라미터 $λ$를 붙여 training data에 fit하게 만드는 것에 더 중점을 둘지, 모델을 단순화하는데 더 중점을 둘지에 대한 trade-off 관계를 설정할 수 있습니다.
* $λ$ 값 높으면 **<span style="color:red">모델이 단순해짐</span>** -> **<span style="color:red">underfitting 위험</span>**
* $λ$ 값 낮으면 **<span style="color:red">모델이 복잡해짐</span>** -> **<span style="color:red">overfitting 위험</span>**

<br>



### Why regularize?

결국 다음과 같은 이유로 Regularization을 사용합니다.
* **<span style="background-color: #fff5b1">가중치에 대한 선호도를 표현하기 위해서.</span>**
* **<span style="background-color: #fff5b1">모델을 simple하게 만들어 test data에서 작동하게 만들기 위해서.</span>**
* **<span style="background-color: #fff5b1">곡면성(curvature)을 추가하여 Optimization을 향상시키기 위해서.</span>**

<br>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182363432-516db31b-1b09-4e20-ba12-f4651d2b08e6.png">
</p>

Regularization 에는 여러 종류들이 있습니다.
* 머신러닝/딥러닝 모두에서 볼 수 있는 것들
    * L2 Regularization(Weight decay) (가장 일반적)
    * L1 Regularization, Elastic net(L1과 L2를 같이 사용), Max norm regularization 등
* 주로 딥러닝에서 볼 수 있는 것들
    * Dropout, Batch normalization, stochastic depth 등



## Regularization: Expressing Preferences

다음 슬라이드는 입력 벡터 $x$와 가중치 벡터 $w$가 있을 때, Linear classification의 관점에서 내적이 같기때문에 $w1$와 $w2$는 같습니다. 출력은 동일하지만 $w$의 형태가 다른 경우를 보여줍니다.
* $w_1^T x = w_2^T x = 1$ 로 모두 동일

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182365578-e550c540-05dd-44ab-8e62-b264f78f515a.png" style="zoom:20%;">
</p>


이때, L1과 L2 regularization이 weight vector가 어떻게 구성되는 것을 더 선호하는지는 L1, L2 norm을 계산해봄으로써 알 수 있습니다.(여기서, 선호한다는 것은 penalty를 덜 준다는 것을 의미)
* **<span style="color:red">L1 norm</span>**
    * $\left\Vert w_1 \right\Vert _1 = \left \vert 1 \right \vert + \left \vert 0 \right \vert + \left \vert 0 \right \vert + \left \vert 0 \right \vert = 1$
    * $\left\Vert w_2 \right\Vert _1 = \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert + \left \vert 0.25 \right \vert = 1$
    * L1 norm이 작게 나오려면 vector의 element들이 0에 가까워야 하므로 sparse해지는 것을 더 선호합니다. (위 예에서는 어쩌다보니 값이 동일하게 나왔음)
* **<span style="color:red">L2 norm</span>**
    * $\left\Vert w_1 \right\Vert _2 = \sqrt{1^2 + 0^2 + 0^2 + 0^2} = 1$
    * $\left\Vert w_2 \right\Vert _2 = \sqrt{0.25^2 + 0.25^2 + 0.25^2 + 0.25^2} = 0.25$
    * L2 norm이 작게 나오려면 vector의 element들이 고르게 분포해야(spread) 하므로 값이 더 넓게 퍼지는 것을 더 선호합니다.
    

따라서, L1과 L2 Regularization이 모델에 미치는 영향에 대한 직관은 다음과 같이 서로 반대라는 것을 알 수 있습니다.
* **<span style="color:red">L1 regularization</span>**
    * **<span style="background-color: #fff5b1">$W$ 가 sparse해지도록 합니다.</span>**
    * **<span style="background-color: #fff5b1">작은 가중치들이 0으로 수렴하게 하고, 몇개의 중요한 가중치만 남도록 합니다.</span>**
    * 가중치 W에 대해 0의 갯수에 따라 모델의 복잡도를 다룹니다.
    * **<span style="background-color: #fff5b1">즉 L1이 "복잡하다"고 느끼고 측정하는 것은 0이 아닌 요소들의 갯수입니다.</span>**
    * 또한 의미 있는 값을 원하면 L1 regularization이 좋습니다.
* **<span style="color:red">L2 regularization</span>**
    * **<span style="background-color: #fff5b1">$W$ 에서 특정 값만 모델에 큰 영향을 미치도록 하지 않습니다. 즉 가중치를 0에 가깝게 유도합니다.</span>**
    * $W$ 의 값이 고르고 넓게 퍼지도록(spread) 합니다. 즉 모든 데이터를 고려합니다.
    * L2 Regression은 분류기의 복잡도를 상대적으로 $w1$와 $w2$중 어떤 것이 더 coarse한지를 측정합니다. (값이 매끄러워야함)
    * Linear classification에서 $W$가 의미하는 것은, "얼마나 $x$가 Output Class와 닮았는지" 이므로, **<span style="background-color: #fff5b1">L2 Regularization이 말하고자 하는것은 $x$의 모든 요소가 영향을 줬으면 하는 것입니다.</span>**
    * 그러므로 변동이 심한 어떤 입력 $x$의 특정 요소에만 의존하기 보다, 모든 $x$의 요소가 골고루 영향을 미치길 원한다면, L2 Regularization을 통해 더 강건합니다.
    * **<span style="background-color: #fff5b1">즉 L2의 경우에는 $W$의 요소가 전체적으로 퍼져있을 때 "덜 복잡하다" 라고 생각하게 됩니다.</span>**

즉, 풀고자 하는 문제에 따라 **<span style="color:red">모델의 복잡도를 어떻게 바라볼 것인가(모델의 복잡도에 어떻게 penalty를 주어서 제한할 것인가)</span>** 를 결정하고, 이에 **<span style="color:red">적절한 regularization을 고르는 것</span>** 이 중요합니다.
* L1
    * w에 0이 아닌 요소가 많을때: 복잡
    * w에 0이 많으면: 덜 복잡
* L2
    * w의 요소가 퍼져있을 때: 덜 복잡
    * w가 어느 쪽에 치중되어 있으면: 복잡


정리하자면 결국 모델을 덜 복잡하게 만들기 위한 것이 Regularization의 궁극적인 목표입니다. 또다른 말로 Hypothesis class중에 더 간단한 것을 선택하기 위해서 우리는 model에 Penalty를 주는 것입니다. 

<br>





#  Softmax Classifier(Multinomial Logistic Regression)

Multi-class SVM loss 외에도 흔히 많이 사용되는 손실함수가 있는데, 바로 Multinomial Logistic regression, 즉 **<span style="color:red">Softmax</span>** 입니다. 딥러닝에서는 일반적으로 softmax를 많이 사용합니다.

어떤 분류문제가 있고 어떤 모델 $F$가 각 클래스에 해당하는 10개의 숫자를 출력할때 **<span style="color:red">multi-class SVM loss</span>** 에서 단지 정답 클래스가 정답이 아닌 클래스들 보다 더 높은 스코어를 내기만을 원했지, 해당 스코어 자체에 대한 해석은 하지않았습니다. **<span style="background-color: #fff5b1">즉, 정답 score과 정답 클래스가 아닌 다른 클래스의 score의 차이(Gap) 에만 집중했지 그 차이가 일정 margin만 넘으면 더 이상 성능 개선에 신경쓰지않습니다.</span>** **<span style="color:red">때문에 스코어 자체가 실제로 의미하는 것에는 관심이 없었습니다.</span>**

반면, **<span style="color:red">multinomial logistic regression(softmax)</span>**의 손실함수는 **<span style="background-color: #fff5b1">score 자체에 추가적인 의미를 부여하는데, 차이를 모두 수치화하여 score에 대한 해석이 가능하게</span>** 합니다. 이때, Softmax 라고 불리는 함수를 쓰고 score를 통해 클래스 별 확률 분포를 계산합니다. 그리고 최종적으로 정답인 클래스의 score가 1과 가깝게 나오는 것을 목표로 합니다. **<span style="color:red">따라서 정답 클래스의 score가 다른 클래스의 score보다 이미 높더라도 계속 해서 더 성능을 좋게 하려고(loss값을 줄이려고) 한다</span>** 는 특징이 있습니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182379478-6e130e03-0f4d-44bb-9101-89c4780fc68f.png">
</p>

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182496820-591f64a3-cccf-488c-9157-c36f45beea4b.png">
</p>

* Softmax Classifier의 Loss 계산 방식
    1. Linear Classifier의 출력으로 나오는 각 클래스에 대한 score에서 exponential 함수를 통해 양수로 만들어 줍니다.
    2. 이후 softmax 함수를 거쳐 (normalize) 모든 score 합이 1이 되도록 하여, 각 score를 probability value로 만들어 줍니다. 각 probability value는 해당 클래스일 확률
        * 즉 앞에서 나온 출력들(probabilities)을 모두 더하면 1이 되도록 normalize한다.
    3. 마지막으로, -log(P(정답클래스)) 값을 취해줍니다.
        * 결국 우리가 원하는 것은 정답 클래스에 해당하는 클래스의 확률이 1에 가깝게 계산되는 것입니다.
        * 확률이 1이 되길 원하는데, 확률값을 최대화 시키는 것 보다 그냥 log로 최대화시키는 것이 더 쉽기 때문에 log를 사용합니다.
        * $-$ 를 붙이는 이유는 loss(손실)로서 모델이 얼마나 나쁜지(BADNESS)를 측정함과 동시에, 최소화 하려는 값이기 때문입니다.
    4. 요약하면, 스코어가 있으면, softmax를 거치고, 나온 확률 값에 -log를 취해주면 됩니다.



## Quiz

### Q1. softmax loss의 최대값과 최소값을 얼마일까요?

* Loss의 최소값은 0 이고 최대값은 $\infty$ 입니다.

확률 분포를 생각해 보면, 우리는 정답 클래스의 확률은 1이 되길 원하고, 정답이 아닌 클래스는 0이 되길 원합니다. 결국 log안에 있는 어떤 값은 결국 1이 되어야 합니다. Loss는 정답 클래스에 대한 Log 확률이기 때문에 원하는 클래스를 완벽히 분류했다면 -Log(1) = 0 이고, Loss는 0이 될 것입니다.

그렇다면 Loss가 0이 되려면 실제 스코어는 어떤 값이어야 할까

아마 정답 스코어는 극단적으로 높아야 할 것입니다. 지수화를 하고 정규화를 하기 때문에 거의 무한대에 가깝게 높아야 합니다. 즉 우리가 확률 1(정답) 과 0(그외) 를 얻으려면, 정답 클래스의 스코어는 +무한대가 되어야 하고, 나머지는 -무한대가 되어야 합니다. 하지만 유한 정밀도 때문에 Loss가 0인 경우는 절대 없을 것이며, 이론적인 해석을 하여 0은 "이론적으로 최소 Loss이다" 라고 이해하면 됩니다.

또한 최대 Loss는 무한대인데, 이론적으로 확률이 0이 되려면 정답 클래스의 스코어가 음의 무한대일 경우 밖에 없으므로 위와같이 유한 정밀도 때문에 Loss가 $\infty$ 인 경우는 절대 없을 것이며, 이론적인 해석을 하여 $\infty$ 는 "이론적으로 최대 Loss이다" 라고 이해하면 됩니다.



### Q2. 훈련을 시작할 때, W를 작은 랜덤값으로 초기화해서 모든 score가 0인 경우의 loss는 어떻게 되나요?

* $\log(\text{class 수})$이다.
    * $e(s)$가 모두 1이 되므로, $-\log( \dfrac{1}{\text{class 수}}) = -\log(1) + \log(class 수) = \log(class 수)$
* 따라서, 훈련 초기에 $\log(\text{class 수})$가 Loss로 나오지 않으면, 잘못되고 있다는 것으로 debugging 할 수 있습니다.

<br>





# Hinge Loss(SVM) vs. Cross-entropy Loss(Softmax)

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182501050-42f37430-13c5-4df7-939c-d0a63e842a6b.png">
</p>

* Hinge Loss와 Cross-entropy Loss의 차이점
    * $Wx + b$의 score를 계산하는 것은 동일하지만, **<span style="background-color: #fff5b1">score를 해석하는 방법이 다릅니다.</span>**
    * **<span style="color:red">Hinge Loss</span>**
        * **<span style="background-color: #fff5b1">정답 class의 score와 정답이 아닌 class의 score를 간의 마진(margins)을 신경썼습니다.</span>**
    * **<span style="color:red">Cross-entropy Loss(softmax)</span>**
        * **<span style="background-color: #fff5b1">probability distribution를 계산하여 score를 확률적으로 해석합니다.</span>**



<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182501385-eb2463fd-88d8-4552-8ef6-d122ab011f58.png">
</p>

* **<span style="color:red">두 Loss함수의 가장 큰 차이점</span>** 은 다음의 질문을 통해 이해할 수 있습니다.
    * Q. 데이터 포인트를 흔들면 어떻게 되나?(SVM Loss에서의 Q1. car의 점수를 변화하면 어떻게 되는가?와 동일)
        * Multiclass SVM Loss는 이미 car의 점수가 커서 loss에 변화가 없음
            * 왜냐면 SVM loss는 오직 정답과 그 외 클래스의 마진이 얼마나 되는지에만 관심이 있기 때문입니다.
            * 즉, margin보다 크기만 하면 더이상 성능 개선에 신경쓰지 않습니다.
        * Cross-entropy Loss에서는 정답 score와 정답이 아닌 score의 차이가 크더라도, 계속해서 그 차이를 크게 만들어 언제나 확률을 1로 만드려고 노력합니다.
            * 즉, 계속해서 개선하려고 하는 경향이 있음





<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182503933-d180950c-9e37-40f9-8aab-72d5ab42ee25.png">
</p>

지금까지 한 것들을 정리하자면 다음과 같습니다.
* 데이터 셋 $(x,y)$이 있습니다.
* 입력 x로부터 스코어를 얻기 위해 Linear classifier, 즉 스코어 함수(score function)를 사용합니다.
    * $s=f(x;W)=Wx$
* softmax, svm loss와 같은 손실함수(loss function)를 이용해서, 모델의 예측값이 정답 값에 비해 얼마나 나쁜지(badness)를 측정합니다.
* 그리고 모델의 "복잡함" 과 "단순함" 을 통제하기 위해 손실 함수에 regularization term을 추가합니다.
* 이 모든걸 합쳐서 최종 손실 함수가 최소가 되게 하는 가중치 행렬이자 파라미터인 W를 구합니다.

<br>





# optimization

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182504788-c349b71d-c7ab-4563-8899-c9ced747398b.png">
</p>


그렇다면 실제로 어떻게 Loss를 줄이는 $W$를 찾아낼 수 있을까? 란 의문이 듭니다. 이 질문은 우리를 "Optimization" 라는 주제로 이끌어 줍니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182505308-4252b172-5dad-4cc2-be56-ba335ad51874.png">
</p>

최적화를 하고 있다는걸 상상해볼때, 우리는 다양한 산과 계곡과 시내가 있는 엄청 큰 골짜기를 거닐고 있을겁니다. 어떻게 해야 실제 loss를 줄일 수 있는 $W$를 찾을 수 있을까? 를 고민해봐야 합니다.
* 그림과 같이 골짜기의 밑바닥을 찾아야 합니다.
    * "산"과 "계곡" 과 같은 풍경들이 바로 파라미터 W입니다.
    * 여기서 loss는 위치의 높이에 해당합니다.
    * loss(높이)는 w의 값에 따라 변합니다.
* 골짜기의 Global한 밑바닥을 찾기위해 다양한 **<span style="background-color: #fff5b1">"iterative한 방법"</span>** 들을 씁니다. **<span style="background-color: #fff5b1">즉 임의의 지점에서 시작해서 점차적으로 성능을 향상시키는 방법</span>** 입니다.


## Strategy #1: A first very bad idea solution: Random search
* 단순한 방법으로 무작위 탐색(random search)이 있습니다.
* 임의로 샘플링한 W들을 모아놓고, 각각의 W 에 대해 loss를 계산해 어떤 W가 좋은지 찾는 것입니다.
* 하지만, 굉장히 좋지 않은 방법이므로 절대 쓰면 안됩니다.



## Strategy #2: Follow the slope

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182507356-59b84bdc-582f-4b76-a283-4aca9054544c.png">
</p>

* 실제로 더 나은 전략은 **<span style="color:red">지역적인 기하학적 특성을 이용하는 것입니다.(local geometry)</span>**
* 위 그림과 같은 계곡에서 눈을 가린 채 가장 낮은 지점을 찾는다고 가정해볼때, 발로 경사가 있는 지점을 찾으면서 계속해서 나아가다 보면, 가장 낮은 지점에 도달할 수 있을 것입니다.
    * 두 발로 땅의 경사를 느끼고, 어느 방향으로 내려가야 할지 판단합니다.
    * 그 방향으로 한발자국 내딛고, 다시 두발로 느끼는 방향을 찾습니다.
    * 구체적으로, 임의의 $W$에서 시작하고, 또 다른 임의의 방향 $δW$으로 살짝 움직여봅니다.
    * 만약 움직여간 자리$(W+δW)$에서의 손실값(loss)가 더 낮으면, 거기로 움직이고 다시 탐색을 시작합니다.
    * 이런 반복으로, 골짜기를 내려갑니다.

<br>



<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182508366-2ce0116c-37f0-4f04-817c-e11c64e3884f.png">
</p>

* **<span style="color:red">경사(slope)</span>**: 1차원 공간에서 어떤 함수에 대한 미분값(derivative)
    * $\frac{df(x)}{dx}=lim_{h→0}\frac{f(x+h)−f(x)}{h}$
    * x를 입력으로 받으면 출력은 곡선의 높이로 생각할 수 있으며, 곡선의 일부를 구하면 기울기를 계산할 수 있습니다.
    * 어떤 점에서의 함수의 경사이므로, 방향(direction) 정보를 가지고 있습니다.
* x는 스칼라가 아니라 벡터이기 때문에 위의 개념을 다변수로 확장시켜야 합니다.
    * x가 벡터일 경우, 이 때 미분을 편미분(partial derivatives)이라 합니다.
    * gradient는 벡터 x의 각 요소를 편미분한 집합입니다.
    * 그레이디언트의 각 요소는 “임의의 방향으로 갈때 함수 f의 경사가 어떤지”의 정보를 알려줍니다.
    * gradient의 방향은 함수에서 "가장 많이 올라가는 방향" 입니다. 반대로 생각해보면, gradient의 반대 방향이라면 "가장 많이 내려갈 수 있는 방향" 입니다. 
    * 만약 특정 방향에서 얼마나 가파른지 알고싶으면, 해당하는 방향의 unit벡터와 gradient벡터의 내적입니다.

**<span style="color:red">gradient가 함수의 어떤점에서의 선형 1차근사 함수를 알려주기 때문에, gradient는 매우 중요합니다.</span>** 실제로 많은 딥러닝 알고리즘들이 gradient를 계산하고, 그 gradient를 여러분들이 파라미터 벡터를 반복적으로 업데이트할 때 사용합니다.

* 즉 정리하면 다음의 과정으로 나타낼 수 있습니다.
    1. parameter vector에 대한 Loss function의 gradient를 계산합니다.
        * gradient는 partial derivatives로 이루어진 vector
    2. gradient에 음의 값을 취한 후, 해당 방향으로 나아간다.
        * 함수의 기울기는 증가에서 $+$, 감소에서 $-$이므로, gradient가 감소하는 방향을 위해 음의 값을 취합니다.

<br>





# Numerical Gradient vs. Analytic Gradient

gradient의 각 요소는 한 방향으로 아주 조금씩 이동했을 때, Loss값이 어떻게 변하는지를 알려주는 것입니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182512234-8c197a2d-79a2-4dbd-bbea-4fcc1332fc6d.png">
</p>

Numerical Gradient는 W의 원소를 아주 조금씩 변화시키면서, gradient를 하나하나 계산하는 방법으로, 위 슬라이드 처럼 아주 작은 값 h를 더해 loss를 다시 계산해 봅니다. 첫 번째 요소를 조금 움직이면 Loss가 1.2534에서 1.25322로 감소합니다. 이후 극한식을 이용해 근사시킨 gradient를 구합니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182513432-bb07d04f-4be0-4178-bc2b-915b068039cc.png">
</p>


* 하지만, 위의 방법은 비효율적이며, 시간이 엄청 오래 걸립니다.
* 즉, Numerical gradient를 사용하지 않고, 함수를 미분해서 loss를 계산하는 Analytic gradient를 사용합니다.
    * **<span style="color:red">Numerical gradient : 근사치(approximate), 느림(slow), 쉬운 방법(easy to write)</span>**
    * **<span style="color:red">Analytic gradient : 정확(fast), 빠름(exact), 실수하기 쉬운(error-prone)</span>**


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182513681-cf67c0a5-bc17-411a-9d66-19b8fcc36840.png">
</p>

위 슬라이드처럼 $W$ 의 모든 원소를 순회하는 것이 아니라 gradient를 나타내는 식이 뭔지만 먼저 찾아내고, 그걸 수식으로 내타내서 한번에 gradient dW를 계산합니다. 즉 Numerical gradient에서보다 훨씬 효율적이고 빠르게 계산이 가능합니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182513985-f2892867-509e-4124-81c1-3355ceb71540.png">
</p>

* 정리하자면 다음과 같습니다.
    * **<span style="color:red">Numerical Gradient</span>**
        * W의 원소를 아주 조금씩 변화시키면서, gradient를 하나하나 계산하는 방법
        * W의 원소 하나하나마다 모두 계산해야 하므로, 너무 느리고 비효율적
    * **<span style="color:red">Analytic Gradient</span>**
        * Loss function은 W에 대한 함수이므로, 그냥 식을 미분해서 gradient를 구하는 방법
        * gradient에 대한 식을 구한 후, dW를 한번에 계산할 수 있으므로 더 빠르고 좋은 방법
* 따라서, 실제로는 Analytic Gradient를 사용하고 Analytic Gradient의 계산 값을 확인하는 debugging 용도로 Numerical Gradient를 사용합니다. -> **<span style="color:red">gradient check</span>**

<br>





# Gradient Descent

* **<span style="color:red">경사 하강법(gradient descent)</span>** : 기울기를 반복적으로 평가한 다음 파라미터 업데이트를 수행하는 절차
    * Loss function 값을 최소화하는 값을 찾는 것으로 기울기의 반대 방향으로 일정 크기만큼 이동하는 것을 반복합니다.
    * 경사 하강을 사용하여 함수의 local minimum을 찾으려면 현재 지점에서 함수의 그레이디언트의 음수에 비례하는 단계를 밟습니다.


```py
# Vanilla Gradient Descent

while True:
    weights_grad = evaluate_gradient(loss_fun, data, weights)
    weights += - step_size * weights_grad # perform parameter update
```

* Gradient Descent 알고리즘
    * W를 임의의 값으로 초기화합니다.
    * Loss와 gradient를 계산한 뒤에 가중치를 gradient의 반대 방향으로 업데이트합니다.
        * gradient가 함수에서 증가하는 방향이기 때문에 -gradient를 해야 내려가는 방향이 됩니다.
    * 스텝사이즈는 Learning rate 라고 하며, 실제 학습시 가장 중요한 하이퍼파라미터 중 하나입니다.


<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182519521-a49aece5-025c-483c-a44c-496b74697db9.png">
</p>

위 그림을 보면 그릇처럼 보이는 것이 손실함수 이며, 가운데 빨간 부분이 낮은 Loss이고, 테두리의 파란영역과 초록 영역은 Loss가 더 높은 곳입니다. 즉 Loss가 높은 곳을 피해가야 합니다.

-gradient를 계산할 것이고 이를 통해 결국 가장 낮은 지점에 도달할 것입니다. 그리고 이걸 계속 반복하게 되면 아마도 결국은 정확한 최저점에 도달하게 될 것입니다. 다음 강의에서 Update Rule을 배울 예정입니다.

<br>





# Mini-batch Stochastic Gradient Descent(SGD, MSGD)

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182521186-ffb27a95-5c72-4e24-9af0-ae7966f5a22a.png">
</p>


Loss function은 각 training sample을 분류기가 얼마나 나쁜지를 계산하는 것이였고, 전체 Loss는 전체 training set Loss의 평균으로 사용했습니다. 하지만 모든 data에 대해 일일히 이 작업을 하기에는 연산량이 너무 많으며, 시간이 오래 걸려 느립니다. 그래서 실제로는 Mini-batch stochastic gradient descent 라는 방법을 씁니다.

* **<span style="color:red">확률적 경사 하강법(Stochastic Gradient Descent; SGD)</span>** : 손실 함수(loss function)을 계산할 때, 전체 데이터(batch) 대신 일부 데이터의 모음(mini-batch)를 사용하는 것
    * 전체 데이터 셋의 gradient과 loss를 계산하기 보다는 Minibatch라는 작은 트레이닝 샘플 집합으로 나눠서 학습하는 것입니다.
    * 미니배치에서 그레이디언트를 구해서 더 자주 가중치를 업데이트하면 더 빠른 수렴 결과를 얻습니다.
    * Minibatch는 보통 2의 승수로 정하며 32, 64, 128 을 보통 씁니다.
    * 즉, 작은 minibatch를 이용해서 Loss의 전체 합의 추정치와 실제 그레이디언트의 추정치를 계산한다.
* 이러한 SGD 학습법은 거의 모든 deep neural network 에서 사용되는 기본적인 학습법이므로 굉장히 중요합니다.

```py
# Vanilla Minibatch Gradient Descent

while True:
    data_batch = sample_training_data(data, 256)
    weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
    weights += - step_size * weights_grad # perform parameter update
```

* Stochastic Gradient Descent 알고리즘
    * 임의의 minibatch를 만들어내고, minibatch에서 Loss와 Gradient를 계산합니다.
    * 이후 W를 업데이트합니다.
    * Loss의 "추정치" 와 Gradient의 "추정치" 를 사용하는 것입니다.

<br>





# Aside: Image Features

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182530295-67c41452-a1ae-48f6-9076-8dabbc709f60.png">
</p>

Deep Neural Network이 유행하기 전에 주로 쓰는 방법으로, Feature Representation을 계산하고 미리 찾은 다음 Linear Classifier 에 넣는 2-stage 방법입니다.
1. 이미지가 있으면 여러가지 Feature Representation을 계산합니다.
    * 이런 Feature Representation은 이미지의 모양새와 관련된 것일 수 있습니다.
2. 여러 특징 표현들을 연결시켜(Concat) 하나의 특징 벡터(feature vector)로 만듭니다.
    * 그러면 이 feature vector가 Linear classifier의 입력으로 사용됩니다.

<br>





# Image Features: Motivation

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182530316-a7f1faa7-2e49-405a-9dee-4e7105d58712.png">
</p>

Image Features의 motivation은 그림과 같은 트레이닝 셋이 있다고 할 때, Linear한 결정 경제를 그릴 방법이 없습니다.

즉, 왼쪽과 같이 raw 한 이미지 자체를 입력으로 넣었을 때에는 linear classifier 로는 분류하지 못했던 이미지 데이터들에 대해, 특징 벡터로 변환하여 입력값으로 넣어줌으로써 linear classifier로 분류가 가능해집니다.

특징 벡터(feature vector)를 뽑아내는 방법은 여러 가지가 있으며, 데이터에 맞게 알맞는 특징 벡터를 사용하면 raw한 이미지에 대해서는 분류가 불가능 했던 것이 특징 벡터로 변환되어 입력되며 분류 가능하게 됩니다. 즉 복잡하던 데이터가, 변환 후에 선형으로 분리가 가능하게 바뀌어서, Linear classifier로 완벽하게 분리할 수 있게 됩니다.



## Example: Color Histogram

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182532146-5fb4ac20-3e2c-4e09-8337-f2b177910cec.png">
</p>

* 각 이미지에서 Hue값만 뽑아서, 모든 픽셀을 어떤 공간에 넣고 각 공간에 담긴 픽셀의 갯수를 세는 방법론입니다.
    * 이는 이미지가 적체적으로 어떤 색인지를 알려줍니다.
    * 컬러 히스토그램은 이미지 전체적으로 어떤 색이 있는지를 나타냅니다.
* 개구리와 같은 경우 자주색이나 붉은색은 별로 없고, 초록색이 많은 것을 알 수 있습니다.

 

## Example: Histogram of Oriented Gradients(HoG)

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182532165-6a9eaa45-7e0e-4f10-af55-5dabb01ee203.png">
</p>

* Hubel 과 Wiesel이 Oriented edges가 인간의 시각시스템에서 정말 중요하다 한 것처럼, Local orientation edges를 측정합니다.
* 이미지를 8*8픽셀로 나눠서 각 픽셀의 지배적인 edge 방향을 계산하고, 각 edge들에 대해서 edge directions을 양자화해서 어떠한 공간에 넣습니다.
    * 다양한 edge oreirentations에 대한 히스토그램을 계산합니다.
    * 이후의 전체 특징 벡터는, 각각의 모든 8x8 지역들이 가진 "edge orientation에 대한 히스토그램" 이 됩니다.
    * HOG는 이미지 내에 전반적으로 어떤 종류의 edge정보가 있는지를 나타냅니다.



## Example: Bag of Words

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182532185-c91a2299-d581-4100-848b-3ef1f3fa12d9.png">
</p>

* 이 방법은 NLP에서 영감을 받은 방식으로, 어떤 문장에서 여러 단어들의 발생빈도를 세서 특징벡터로 사용하는 방식을 이미지에 적용한 것입니다.
* 시각 단어(visual words)를 위한 2단계의 과정
    1. 엄청 많은 이미지들을 임의대로 조각낸 후 그 조각들을 K-means와 같은 알고리즘으로 군집화합니다.
        * 이미지내의 다양한 것들을 표현할 수 있는 다양한 군집들을 만들어 냅니다.
        * 군집화 단계를 거치고나면, 시각 단어(visual words)는 빨간색, 파랑색, 노랑색과 같은 다양한 색을 포착해냅니다.
        * 또한 다양한 종류의 다양한 방향의  oriented edges또한 포착할 수 있습니다.
    2. 시각 단어(visual words) 집합을 만들어 떤 이미지에서의 시각 단어들의 발생 빈도를 통해서 이미지를 인코딩 합니다.
        * 이 이미지가 어떻게 생겼는지에 대한 다양한 정보를 제공하는 것입니다.

<br>





# Image features vs ConvNets

Image classification의 **<span style="color:red">pipleline</span>**은 다음과 같습니다.

CNN 이 나오기 전에는 이런 방식으로 이미지에서 특징 벡터(feature vector)를 추출하고 이후에 classifier를 학습시켜서 분류를 하는 2-stage 방식으로 진행됐었습니다.

이러한 방법은 feature extractor를 통해 특징 벡터가 한번 추출되고 나면 이후 classifier 학습 과정에서 해당 feature extractor가 변하지 않는다는 것입니다. 즉, 학습과정에서 classifier만 학습됩니다.

<p align="center">
<img alt="image" src="https://user-images.githubusercontent.com/77891754/182534485-0573d266-ece9-4e4c-961f-0b7b4d69534b.png">
</p>

반면, **<span style="color:red">CNN</span>**(Convolutional Neural Network)이나 **<span style="color:red">DNN</span>**(Deep Neural Network)에서는 **<span style="background-color: #fff5b1">미리 정해놓은 특징을 쓰는 것이 아니라, raw 한 입력 이미지 데이터로부터 직접 feature들을 학습하여 특징 표현들을 직접 만들어냅니다.</span>** **<span style="color:red">따라서 Linear classifier만 훈련하는게 아니라 가중치 전체를 한꺼번에 학습하는 1-stage 방법론</span>**입니다.

다음시간에는 Neural Networks에 대해 살펴볼 것이고, 역전파(Backpropagation)에 대해서 살펴보겠습니다.




